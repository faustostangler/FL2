{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "import requests\n",
    "import yfinance as yf\n",
    "\n",
    "import string\n",
    "import random\n",
    "import unidecode\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DADOAS ABEERTOS DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import zipfile\n",
    "import io\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL and report types\n",
    "base_url = \"https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/\"\n",
    "reports = [\"ITR\", \"DFP\"]\n",
    "\n",
    "data_folder = r\"D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Container for the extracted data\n",
    "zip_files = []\n",
    "\n",
    "# Iterate over report types and collect .zip file URLs\n",
    "for report_type in reports:\n",
    "    url = f\"{base_url}{report_type}/DADOS/\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensure the request is successful\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extract all .zip links\n",
    "    zip_files.extend(\n",
    "        [\n",
    "            url + a[\"href\"]\n",
    "            for a in soup.find_all(\"a\", href=True)\n",
    "            if a[\"href\"].endswith(\".zip\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/itr_cia_aberta_2011.zip\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_BPA_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_BPA_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_BPP_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_BPP_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DFC_MD_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DFC_MD_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DFC_MI_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DFC_MI_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DMPL_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DMPL_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DRA_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DRA_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DRE_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DRE_ind_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DVA_con_2011.csv\n",
      "D:\\Fausto Stangler\\Documentos\\Python\\FLY\\backend\\data\\itr_cia_aberta_DVA_ind_2011.csv\n"
     ]
    }
   ],
   "source": [
    "level_skip = \"no_level\"\n",
    "keywords = [\"ind\", \"con\"]\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "for zip_url in zip_files:\n",
    "    print(f\"{zip_url}\")\n",
    "    try:\n",
    "        # Determine a cache file path based on the URL\n",
    "        cached_file_path = os.path.join(data_folder, os.path.basename(zip_url))\n",
    "\n",
    "        # Check if the file is already cached\n",
    "        if os.path.exists(cached_file_path):\n",
    "            with open(cached_file_path, \"rb\") as cached_file:\n",
    "                content = cached_file.read()\n",
    "        else:\n",
    "            print(f\"Downloading: {zip_url}\")\n",
    "            # Request the .zip file\n",
    "            response = requests.get(zip_url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Save to cache after validation\n",
    "            content = response.content\n",
    "            with open(cached_file_path, \"wb\") as cached_file:\n",
    "                cached_file.write(content)\n",
    "\n",
    "        # Open the .zip file\n",
    "        with zipfile.ZipFile(io.BytesIO(content)) as z:\n",
    "            # List all files in the ZIP archive\n",
    "            file_names = z.namelist()\n",
    "            for file_name in file_names:\n",
    "                try:\n",
    "                    # Check if the file is a CSV or another readable format\n",
    "                    if file_name.endswith(\".csv\") and any(\n",
    "                        keyword in file_name for keyword in keywords\n",
    "                    ):\n",
    "                        # Parse the filename for year, level, and type\n",
    "                        parts = file_name.split(\"_\")\n",
    "                        year = parts[-1].split(\".\")[0]  # Extract the year\n",
    "                        level = parts[-2] if parts[-2] in [\"con\", \"ind\"] else level_skip\n",
    "                        doc_type = parts[-3] if level in [\"con\", \"ind\"] else parts[-2]\n",
    "\n",
    "                        # Construct the path to the file\n",
    "                        file_path = os.path.join(data_folder, file_name)\n",
    "                        print(f\"{file_path}\")\n",
    "\n",
    "                        # Read the CSV into a DataFrame\n",
    "                        with z.open(file_name) as f:\n",
    "                            # df = pd.read_csv(f, encoding='latin1', sep=';', error_bad_lines=False)\n",
    "                            df = pd.read_csv(\n",
    "                                f, encoding=\"latin1\", sep=\";\"\n",
    "                            )  # Read CSV file\n",
    "\n",
    "                            # Initialize nested dictionaries as needed\n",
    "                            if year not in dataframes:\n",
    "                                dataframes[year] = {}\n",
    "                            if doc_type not in dataframes[year]:\n",
    "                                dataframes[year][doc_type] = {}\n",
    "\n",
    "                            # Store the DataFrame in the appropriate place\n",
    "                            if level != level_skip:\n",
    "                                dataframes[year][doc_type][level] = df\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {zip_url}: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['BPA', 'BPP', 'MD', 'MI', 'DMPL', 'DRA', 'DRE', 'DVA'])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[\"2011\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataframes[\"2011\"][\"BPA\"][\"con\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNPJ_CIA</th>\n",
       "      <th>DT_REFER</th>\n",
       "      <th>VERSAO</th>\n",
       "      <th>DENOM_CIA</th>\n",
       "      <th>CD_CVM</th>\n",
       "      <th>GRUPO_DFP</th>\n",
       "      <th>MOEDA</th>\n",
       "      <th>ESCALA_MOEDA</th>\n",
       "      <th>ORDEM_EXERC</th>\n",
       "      <th>DT_FIM_EXERC</th>\n",
       "      <th>CD_CONTA</th>\n",
       "      <th>DS_CONTA</th>\n",
       "      <th>VL_CONTA</th>\n",
       "      <th>ST_CONTA_FIXA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00.001.180/0001-26</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRAIS ELET BRAS S.A. - ELETROBRAS</td>\n",
       "      <td>2437</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>Ativo Total</td>\n",
       "      <td>149751700.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00.001.180/0001-26</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRAIS ELET BRAS S.A. - ELETROBRAS</td>\n",
       "      <td>2437</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Ativo Circulante</td>\n",
       "      <td>34736318.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00.001.180/0001-26</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRAIS ELET BRAS S.A. - ELETROBRAS</td>\n",
       "      <td>2437</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1.01.01</td>\n",
       "      <td>Caixa e Equivalentes de Caixa</td>\n",
       "      <td>12358365.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00.001.180/0001-26</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRAIS ELET BRAS S.A. - ELETROBRAS</td>\n",
       "      <td>2437</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1.01.01.01</td>\n",
       "      <td>Caixa e equivalente de caixa</td>\n",
       "      <td>9763580.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00.001.180/0001-26</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>CENTRAIS ELET BRAS S.A. - ELETROBRAS</td>\n",
       "      <td>2437</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>1.01.01.02</td>\n",
       "      <td>Caixa restrito</td>\n",
       "      <td>2594785.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135861</th>\n",
       "      <td>97.837.181/0001-47</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>DEXCO S.A.</td>\n",
       "      <td>21091</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1.02.04.01.03</td>\n",
       "      <td>Softwares, marcas e patentes</td>\n",
       "      <td>28262.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135863</th>\n",
       "      <td>97.837.181/0001-47</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>DEXCO S.A.</td>\n",
       "      <td>21091</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1.02.04.02</td>\n",
       "      <td>Goodwill</td>\n",
       "      <td>226819.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135865</th>\n",
       "      <td>97.837.181/0001-47</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>DEXCO S.A.</td>\n",
       "      <td>21091</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1.02.04.02.01</td>\n",
       "      <td>Goodwill na associação da Satipel em 2009</td>\n",
       "      <td>187573.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135867</th>\n",
       "      <td>97.837.181/0001-47</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>DEXCO S.A.</td>\n",
       "      <td>21091</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1.02.04.02.02</td>\n",
       "      <td>Goodwill na aquisição Cerâmica Monte Carlo em ...</td>\n",
       "      <td>22154.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135869</th>\n",
       "      <td>97.837.181/0001-47</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>DEXCO S.A.</td>\n",
       "      <td>21091</td>\n",
       "      <td>DF Consolidado - Balanço Patrimonial Ativo</td>\n",
       "      <td>REAL</td>\n",
       "      <td>MIL</td>\n",
       "      <td>ÚLTIMO</td>\n",
       "      <td>2011-09-30</td>\n",
       "      <td>1.02.04.02.03</td>\n",
       "      <td>Goodwill na aquisição da Deca Nordeste em 2011</td>\n",
       "      <td>17092.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68055 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CNPJ_CIA    DT_REFER  VERSAO  \\\n",
       "1       00.001.180/0001-26  2011-03-31       1   \n",
       "3       00.001.180/0001-26  2011-03-31       1   \n",
       "5       00.001.180/0001-26  2011-03-31       1   \n",
       "7       00.001.180/0001-26  2011-03-31       1   \n",
       "9       00.001.180/0001-26  2011-03-31       1   \n",
       "...                    ...         ...     ...   \n",
       "135861  97.837.181/0001-47  2011-09-30       1   \n",
       "135863  97.837.181/0001-47  2011-09-30       1   \n",
       "135865  97.837.181/0001-47  2011-09-30       1   \n",
       "135867  97.837.181/0001-47  2011-09-30       1   \n",
       "135869  97.837.181/0001-47  2011-09-30       1   \n",
       "\n",
       "                                   DENOM_CIA  CD_CVM  \\\n",
       "1       CENTRAIS ELET BRAS S.A. - ELETROBRAS    2437   \n",
       "3       CENTRAIS ELET BRAS S.A. - ELETROBRAS    2437   \n",
       "5       CENTRAIS ELET BRAS S.A. - ELETROBRAS    2437   \n",
       "7       CENTRAIS ELET BRAS S.A. - ELETROBRAS    2437   \n",
       "9       CENTRAIS ELET BRAS S.A. - ELETROBRAS    2437   \n",
       "...                                      ...     ...   \n",
       "135861                            DEXCO S.A.   21091   \n",
       "135863                            DEXCO S.A.   21091   \n",
       "135865                            DEXCO S.A.   21091   \n",
       "135867                            DEXCO S.A.   21091   \n",
       "135869                            DEXCO S.A.   21091   \n",
       "\n",
       "                                         GRUPO_DFP MOEDA ESCALA_MOEDA  \\\n",
       "1       DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "3       DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "5       DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "7       DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "9       DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "...                                            ...   ...          ...   \n",
       "135861  DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "135863  DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "135865  DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "135867  DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "135869  DF Consolidado - Balanço Patrimonial Ativo  REAL          MIL   \n",
       "\n",
       "       ORDEM_EXERC DT_FIM_EXERC       CD_CONTA  \\\n",
       "1           ÚLTIMO   2011-03-31              1   \n",
       "3           ÚLTIMO   2011-03-31           1.01   \n",
       "5           ÚLTIMO   2011-03-31        1.01.01   \n",
       "7           ÚLTIMO   2011-03-31     1.01.01.01   \n",
       "9           ÚLTIMO   2011-03-31     1.01.01.02   \n",
       "...            ...          ...            ...   \n",
       "135861      ÚLTIMO   2011-09-30  1.02.04.01.03   \n",
       "135863      ÚLTIMO   2011-09-30     1.02.04.02   \n",
       "135865      ÚLTIMO   2011-09-30  1.02.04.02.01   \n",
       "135867      ÚLTIMO   2011-09-30  1.02.04.02.02   \n",
       "135869      ÚLTIMO   2011-09-30  1.02.04.02.03   \n",
       "\n",
       "                                                 DS_CONTA     VL_CONTA  \\\n",
       "1                                             Ativo Total  149751700.0   \n",
       "3                                        Ativo Circulante   34736318.0   \n",
       "5                           Caixa e Equivalentes de Caixa   12358365.0   \n",
       "7                            Caixa e equivalente de caixa    9763580.0   \n",
       "9                                          Caixa restrito    2594785.0   \n",
       "...                                                   ...          ...   \n",
       "135861                       Softwares, marcas e patentes      28262.0   \n",
       "135863                                           Goodwill     226819.0   \n",
       "135865          Goodwill na associação da Satipel em 2009     187573.0   \n",
       "135867  Goodwill na aquisição Cerâmica Monte Carlo em ...      22154.0   \n",
       "135869     Goodwill na aquisição da Deca Nordeste em 2011      17092.0   \n",
       "\n",
       "       ST_CONTA_FIXA  \n",
       "1                  S  \n",
       "3                  S  \n",
       "5                  S  \n",
       "7                  N  \n",
       "9                  N  \n",
       "...              ...  \n",
       "135861             N  \n",
       "135863             S  \n",
       "135865             N  \n",
       "135867             N  \n",
       "135869             N  \n",
       "\n",
       "[68055 rows x 14 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[\"ORDEM_EXERC\"] != \"PENÚLTIMO\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import content as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process df to match statements columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as some appropriate format, maybe check nsd numbers or something yet to be defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENET DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get new NSD ENET list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all nsd and filter only ITR and DFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all saved-reports-nsd and exclude saved-reports-nsd from all-nsd list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download enet nsd-new reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open nsd page, get info and generate enet download link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download enet zip, open and read xls and delete zip and other files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### process and clean xls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### incremental save nsd reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update saved-reports-nsd list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_dfs_types(\n",
    "    df,\n",
    "    source_type=\"Dados da Empresa\",\n",
    "    target_types=[\"DFs Consolidadas\", \"DFs Individuais\"],\n",
    "):\n",
    "    \"\"\"\n",
    "    Duplica condicionalmente as linhas de um tipo específico para outros tipos,\n",
    "    baseando-se na existência prévia desses tipos para a mesma empresa e quarter.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df (pd.DataFrame): DataFrame original contendo os dados financeiros.\n",
    "    - source_type (str): O tipo de linha que será duplicado. Padrão: 'Dados da Empresa'.\n",
    "    - target_types (list of str): Lista dos tipos para os quais as linhas serão duplicadas.\n",
    "                                   Padrão: ['DFs Consolidadas', 'DFs Individuais'].\n",
    "\n",
    "    Retorna:\n",
    "    - pd.DataFrame: DataFrame atualizado com as duplicações condicionais.\n",
    "    \"\"\"\n",
    "\n",
    "    # Passo 1: Identificar combinações existentes de company_name e quarter para cada target_type\n",
    "    existing_combinations = {}\n",
    "    for target in target_types:\n",
    "        existing_keys = df[df[\"type\"] == target][\n",
    "            [\"company_name\", \"quarter\"]\n",
    "        ].drop_duplicates()\n",
    "        existing_combinations[target] = existing_keys\n",
    "\n",
    "    # Passo 2: Filtrar as linhas do source_type\n",
    "    source_df = df[df[\"type\"] == source_type].copy()\n",
    "\n",
    "    # Passo 3: Para cada target_type, verificar onde duplicar\n",
    "    duplicated_dfs = []\n",
    "    for target in target_types:\n",
    "        # Obter as combinações onde já existe o target_type\n",
    "        target_keys = existing_combinations[target]\n",
    "\n",
    "        # Realizar um merge para identificar quais linhas do source_df têm a combinação existente\n",
    "        to_duplicate = source_df.merge(\n",
    "            target_keys,\n",
    "            on=[\"company_name\", \"quarter\"],\n",
    "            how=\"inner\",\n",
    "            suffixes=(\"\", \"_target\"),\n",
    "        )\n",
    "\n",
    "        if not to_duplicate.empty:\n",
    "            # Duplicar as linhas e alterar o type para o target_type\n",
    "            duplicated = to_duplicate.copy()\n",
    "            duplicated[\"type\"] = target\n",
    "            duplicated_dfs.append(duplicated)\n",
    "            # print(f\"Duplicando {len(duplicated)} linhas para o tipo '{target}'.\")\n",
    "        else:\n",
    "            # print(f\"Nenhuma duplicação necessária para o tipo '{target}'.\")\n",
    "            pass\n",
    "\n",
    "    # Passo 4: Concatenar todas as duplicações\n",
    "    if duplicated_dfs:\n",
    "        duplicated_df = pd.concat(duplicated_dfs, ignore_index=True)\n",
    "    else:\n",
    "        duplicated_df = pd.DataFrame(columns=df.columns)\n",
    "        # print(\"Nenhuma duplicação realizada.\")\n",
    "\n",
    "    # Passo 5: Remover as linhas originais do source_type\n",
    "    df_filtered = df[df[\"type\"] != source_type].copy()\n",
    "\n",
    "    # Passo 6: Adicionar as duplicações ao DataFrame\n",
    "    if not duplicated_df.empty:\n",
    "        df_updated = pd.concat([df_filtered, duplicated_df], ignore_index=True)\n",
    "    else:\n",
    "        df_updated = df_filtered.copy()\n",
    "\n",
    "    # Passo 7: Resetar o índice e ordenar o DataFrame (opcional)\n",
    "    df_updated.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Passo 8: Ordenar o DataFrame\n",
    "    df_updated = df_updated.sort_values(\n",
    "        by=[\n",
    "            \"sector\",\n",
    "            \"subsector\",\n",
    "            \"segment\",\n",
    "            \"company_name\",\n",
    "            \"quarter\",\n",
    "            \"version\",\n",
    "            \"type\",\n",
    "            \"account\",\n",
    "            \"description\",\n",
    "        ]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators(df, frame_name, indicator_list):\n",
    "    \"\"\"\n",
    "    Calcula indicadores financeiros e os adiciona como novas linhas no DataFrame.\n",
    "\n",
    "    Parâmetros:\n",
    "    - df (pd.DataFrame): DataFrame original contendo os dados financeiros.\n",
    "    - indicator_list (list of dict): Lista de dicionários com definições dos indicadores.\n",
    "\n",
    "    Retorna:\n",
    "    - pd.DataFrame: DataFrame atualizado com as novas linhas de indicadores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Função para realizar divisão segura\n",
    "    def safe_division(numerator, denominator):\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            result = numerator / denominator\n",
    "            result = result.replace(\n",
    "                [np.inf, -np.inf], np.nan\n",
    "            )  # Substitui infinitos por NaN\n",
    "            return result\n",
    "\n",
    "    # Passo 1: Pivotar o DataFrame com contas como colunas e incluir 'quarter' no índice\n",
    "    pivot_df = df.pivot_table(\n",
    "        index=[\"company_name\", \"type\", \"quarter\"],\n",
    "        columns=\"account\",\n",
    "        values=\"value\",\n",
    "        aggfunc=\"sum\",\n",
    "        fill_value=0,  # Substitui valores ausentes por 0\n",
    "    ).reset_index()\n",
    "\n",
    "    # print(\"Colunas do DataFrame Pivotado:\", pivot_df.columns.tolist())\n",
    "\n",
    "    # Passo 2: Calcular os Indicadores\n",
    "    for indicator in indicator_list:\n",
    "        column_name = indicator[\"description\"]\n",
    "        column_account = indicator[\"account\"]\n",
    "        try:\n",
    "            # Aplicar a fórmula para calcular o indicador\n",
    "            pivot_df[column_name] = indicator[\"formula\"](pivot_df)\n",
    "            # print(f\"Indicador '{column_name}' calculado com sucesso.\")\n",
    "        except KeyError as e:\n",
    "            print(f\"'{column_account} - {column_name}': a conta {e} não existe\")\n",
    "            pivot_df[column_name] = np.nan  # Atribuir NaN se a coluna não existir\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"{column_name}': {e} Erro ao calcular o indicador '{column_name}': {e}\"\n",
    "            )\n",
    "            pivot_df[column_name] = np.nan  # Atribuir NaN em caso de erro\n",
    "\n",
    "    # Passo 3: Criar Novas Linhas para os Indicadores\n",
    "    new_rows = []\n",
    "\n",
    "    for indicator in indicator_list:\n",
    "        account = indicator[\"account\"]\n",
    "        description = indicator[\"description\"]\n",
    "\n",
    "        if description not in pivot_df.columns:\n",
    "            print(\n",
    "                f\"Aviso: Indicador '{description}' não foi calculado e será ignorado.\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Extrair os valores calculados do indicador\n",
    "        pivot_df[\"value\"] = pivot_df[description]\n",
    "\n",
    "        # Selecionar as colunas relevantes\n",
    "        indicator_values = pivot_df[[\"company_name\", \"type\", \"quarter\", \"value\"]].copy()\n",
    "        indicator_values[\"account\"] = account\n",
    "        indicator_values[\"description\"] = description\n",
    "\n",
    "        # Atribuir 'frame' como 'Indicadores' para identificar facilmente as novas linhas\n",
    "        indicator_values[\"frame\"] = frame_name\n",
    "\n",
    "        # Preencher as colunas faltantes com informações do DataFrame original\n",
    "        # Selecionar combinações únicas de 'company_name', 'type' e 'quarter'\n",
    "        metadata = df[\n",
    "            [\n",
    "                \"company_name\",\n",
    "                \"type\",\n",
    "                \"quarter\",\n",
    "                \"nsd\",\n",
    "                \"sector\",\n",
    "                \"subsector\",\n",
    "                \"segment\",\n",
    "                \"version\",\n",
    "            ]\n",
    "        ].drop_duplicates(subset=[\"company_name\", \"type\", \"quarter\"], keep=\"first\")\n",
    "\n",
    "        # Mesclar com 'metadata' para preencher 'nsd', 'sector', etc.\n",
    "        indicator_row = indicator_values.merge(\n",
    "            metadata, on=[\"company_name\", \"type\", \"quarter\"], how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Reordenar as colunas para corresponder ao DataFrame original\n",
    "        indicator_row = indicator_row[\n",
    "            [\n",
    "                \"nsd\",\n",
    "                \"sector\",\n",
    "                \"subsector\",\n",
    "                \"segment\",\n",
    "                \"company_name\",\n",
    "                \"quarter\",\n",
    "                \"version\",\n",
    "                \"type\",\n",
    "                \"frame\",\n",
    "                \"account\",\n",
    "                \"description\",\n",
    "                \"value\",\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        # Adicionar à lista de novas linhas\n",
    "        new_rows.append(indicator_row)\n",
    "\n",
    "    # Combinar todas as novas linhas de indicadores\n",
    "    if new_rows:\n",
    "        new_rows_df = pd.concat(new_rows, ignore_index=True)\n",
    "    else:\n",
    "        new_rows_df = pd.DataFrame(columns=df.columns)\n",
    "        # print(\"Nenhum indicador foi adicionado.\")\n",
    "\n",
    "    # Passo 4: Adicionar as Novas Linhas ao DataFrame Original\n",
    "    updated_df = pd.concat([df, new_rows_df], ignore_index=True)\n",
    "\n",
    "    # Passo 5: Tratamento Final dos Valores\n",
    "    # Opcional: Preencher valores faltantes ou realizar outras limpezas\n",
    "    # Exemplo: Substituir NaN por zero onde apropriado\n",
    "    # updated_df['value'] = updated_df['value'].fillna(0)\n",
    "\n",
    "    return updated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'settings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[139], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m sector \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMUNICACOES\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m db_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43msettings\u001b[49m\u001b[38;5;241m.\u001b[39mdb_filepath\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msettings\u001b[38;5;241m.\u001b[39mstatements_standard\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(db_file)\n\u001b[0;32m      5\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'settings' is not defined"
     ]
    }
   ],
   "source": [
    "sector = \"COMUNICACOES\"\n",
    "db_file = (\n",
    "    f\"..\\data\\{settings.db_filepath.split('.')[0]} {settings.statements_standard}.db\"\n",
    ")\n",
    "\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch all table names excluding internal SQLite tables\n",
    "cursor.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\"\n",
    ")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {sector}\", conn)\n",
    "# df['account_description'] = df['account'] + ' - ' + df['description']\n",
    "df[\"quarter\"] = pd.to_datetime(df[\"quarter\"])\n",
    "\n",
    "# df = clean_dados_da_empresa(df)\n",
    "df = duplicate_dfs_types(df)\n",
    "\n",
    "# Store unique values\n",
    "uv = {}\n",
    "for col in df.columns:\n",
    "    if col not in [\"nsd\", \"value\"]:\n",
    "        uv[col] = sorted(df[col].unique().tolist())\n",
    "\n",
    "df[[\"account\", \"description\"]].drop_duplicates().to_csv(\n",
    "    \"account-description.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of indicator formulas\n",
    "indicators_08 = [\n",
    "    {\n",
    "        \"account\": \"08.01\",\n",
    "        \"description\": \"ROE Return On Equity\",\n",
    "        \"formula\": lambda df: df[\"03.11\"]\n",
    "        / df[\"02.03\"]\n",
    "        * 10000,  # ROE = Net Profit / Shareholders' Equity * 100\n",
    "    },\n",
    "    {\n",
    "        \"account\": \"08.02\",\n",
    "        \"description\": \"Índice de Liquidez Corrente\",\n",
    "        \"formula\": lambda df: df[\"01.01\"]\n",
    "        / df[\"02.01\"],  # Current Ratio = Current Assets / Current Liabilities\n",
    "    },\n",
    "    # Add more indicators as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_indicators(df, \"Indicadores Fundamentalistas\", indicators_08)\n",
    "# Store unique values\n",
    "uvi = {}\n",
    "for col in df.columns:\n",
    "    if col not in [\"nsd\", \"value\"]:\n",
    "        uvi[col] = sorted(df[col].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df[\"company_name\"] == uvi[\"company_name\"][7]\n",
    "mask &= df[\"type\"] == uvi[\"type\"][1]\n",
    "mask &= df[\"account\"] == \"08.02\"\n",
    "# mask &= df2['quarter'] == '2020-12-31'\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [col for col in df2.columns if col not in [\"quarter\", \"value\"]]\n",
    "\n",
    "# Verificar duplicatas\n",
    "duplicatas = df2.duplicated(subset=index_cols + [\"quarter\"], keep=False)\n",
    "num_duplicatas = duplicatas.sum()\n",
    "\n",
    "if num_duplicatas > 0:\n",
    "    print(\"Agregando duplicatas somando os valores.\")\n",
    "    df2_agregado = df2.groupby(index_cols + [\"quarter\"], as_index=False)[\"value\"].sum()\n",
    "    # df2_agregado = df2.groupby(index_cols + ['quarter'], as_index=False)['value'].mean() # opcionalmente calcular a média\n",
    "\n",
    "else:\n",
    "    df2_agregado = df2.copy()\n",
    "\n",
    "# Pivotar o DataFrame\n",
    "df_pivot = df2_agregado.pivot_table(\n",
    "    index=index_cols,\n",
    "    columns=\"quarter\",\n",
    "    values=\"value\",\n",
    "    aggfunc=\"first\",  # 'first' assume que não há duplicatas após a agregação\n",
    ").reset_index()\n",
    "\n",
    "# # Obter uma lista dos quarters únicos, ordenados de forma decrescente\n",
    "# sorted_quarters = sorted(df_pivot.columns[ len(index_cols): ], reverse=True)\n",
    "\n",
    "# # Reordenar as colunas: primeiro os índices, depois os quarters em ordem decrescente\n",
    "# df_pivot = df_pivot[index_cols + sorted_quarters]\n",
    "\n",
    "# # Opcional: formatar os nomes das colunas de quarter para strings legíveis\n",
    "# df_pivot.columns = list(index_cols) + [q.strftime('%Y-%m-%d') for q in sorted_quarters]\n",
    "\n",
    "df_pivot.fillna(0, inplace=True)\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot.iloc[0:1,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = \"COMUNICACOES\"\n",
    "db_file = (\n",
    "    f\"..\\data\\{settings.db_filepath.split('.')[0]} {settings.statements_standard}.db\"\n",
    ")\n",
    "\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch all table names excluding internal SQLite tables\n",
    "cursor.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\"\n",
    ")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {sector}\", conn)\n",
    "# df['account_description'] = df['account'] + ' - ' + df['description']\n",
    "df[\"quarter\"] = pd.to_datetime(df[\"quarter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sector': ['COMUNICACOES'],\n",
       " 'subsector': ['MIDIA', 'TELECOMUNICACOES'],\n",
       " 'segment': ['PUBLICIDADE E PROPAGANDA', 'TELECOMUNICACOES'],\n",
       " 'company_name': ['ALGAR TELECOM SA',\n",
       "  'BRISANET PARTICIPACOES SA',\n",
       "  'DESKTOP SA',\n",
       "  'ELETROMIDIA SA',\n",
       "  'GIGA MAIS FIBRA TELECOMUNICACOES SA',\n",
       "  'OI SA',\n",
       "  'TELEC BRASILEIRAS SA TELEBRAS',\n",
       "  'TELEFONICA BRASIL SA',\n",
       "  'TIM SA',\n",
       "  'UNIFIQUE TELECOMUNICACOES SA'],\n",
       " 'quarter': [Timestamp('2010-12-31 00:00:00'),\n",
       "  Timestamp('2011-03-31 00:00:00'),\n",
       "  Timestamp('2011-06-30 00:00:00'),\n",
       "  Timestamp('2011-09-30 00:00:00'),\n",
       "  Timestamp('2011-12-31 00:00:00'),\n",
       "  Timestamp('2012-03-31 00:00:00'),\n",
       "  Timestamp('2012-06-30 00:00:00'),\n",
       "  Timestamp('2012-09-30 00:00:00'),\n",
       "  Timestamp('2012-12-31 00:00:00'),\n",
       "  Timestamp('2013-03-31 00:00:00'),\n",
       "  Timestamp('2013-06-30 00:00:00'),\n",
       "  Timestamp('2013-09-30 00:00:00'),\n",
       "  Timestamp('2013-12-31 00:00:00'),\n",
       "  Timestamp('2014-03-31 00:00:00'),\n",
       "  Timestamp('2014-06-30 00:00:00'),\n",
       "  Timestamp('2014-09-30 00:00:00'),\n",
       "  Timestamp('2014-12-31 00:00:00'),\n",
       "  Timestamp('2015-03-31 00:00:00'),\n",
       "  Timestamp('2015-06-30 00:00:00'),\n",
       "  Timestamp('2015-09-30 00:00:00'),\n",
       "  Timestamp('2015-12-31 00:00:00'),\n",
       "  Timestamp('2016-03-31 00:00:00'),\n",
       "  Timestamp('2016-06-30 00:00:00'),\n",
       "  Timestamp('2016-09-30 00:00:00'),\n",
       "  Timestamp('2016-12-31 00:00:00'),\n",
       "  Timestamp('2017-03-31 00:00:00'),\n",
       "  Timestamp('2017-06-30 00:00:00'),\n",
       "  Timestamp('2017-09-30 00:00:00'),\n",
       "  Timestamp('2017-12-31 00:00:00'),\n",
       "  Timestamp('2018-03-31 00:00:00'),\n",
       "  Timestamp('2018-06-30 00:00:00'),\n",
       "  Timestamp('2018-09-30 00:00:00'),\n",
       "  Timestamp('2018-12-31 00:00:00'),\n",
       "  Timestamp('2019-03-31 00:00:00'),\n",
       "  Timestamp('2019-06-30 00:00:00'),\n",
       "  Timestamp('2019-09-30 00:00:00'),\n",
       "  Timestamp('2019-12-31 00:00:00'),\n",
       "  Timestamp('2020-03-31 00:00:00'),\n",
       "  Timestamp('2020-06-30 00:00:00'),\n",
       "  Timestamp('2020-09-30 00:00:00'),\n",
       "  Timestamp('2020-12-31 00:00:00'),\n",
       "  Timestamp('2021-03-31 00:00:00'),\n",
       "  Timestamp('2021-06-30 00:00:00'),\n",
       "  Timestamp('2021-09-30 00:00:00'),\n",
       "  Timestamp('2021-12-31 00:00:00'),\n",
       "  Timestamp('2022-03-31 00:00:00'),\n",
       "  Timestamp('2022-06-30 00:00:00'),\n",
       "  Timestamp('2022-09-30 00:00:00'),\n",
       "  Timestamp('2022-12-31 00:00:00'),\n",
       "  Timestamp('2023-03-31 00:00:00'),\n",
       "  Timestamp('2023-06-30 00:00:00'),\n",
       "  Timestamp('2023-09-30 00:00:00'),\n",
       "  Timestamp('2023-12-31 00:00:00'),\n",
       "  Timestamp('2024-03-31 00:00:00'),\n",
       "  Timestamp('2024-06-30 00:00:00')],\n",
       " 'version': ['1', '2', '3', '4'],\n",
       " 'type': ['DFs Consolidadas', 'DFs Individuais', 'Dados da Empresa'],\n",
       " 'frame': ['Balanço Patrimonial Ativo',\n",
       "  'Balanço Patrimonial Passivo',\n",
       "  'Composição do Capital',\n",
       "  'Demonstração de Valor Adicionado',\n",
       "  'Demonstração do Fluxo de Caixa',\n",
       "  'Demonstração do Resultado'],\n",
       " 'account': ['00.01.01',\n",
       "  '00.01.02',\n",
       "  '00.02.01',\n",
       "  '00.02.02',\n",
       "  '01',\n",
       "  '01.01',\n",
       "  '01.01.01',\n",
       "  '01.01.01.01',\n",
       "  '01.01.01.02',\n",
       "  '01.01.02',\n",
       "  '01.01.02.01',\n",
       "  '01.01.02.02',\n",
       "  '01.01.03',\n",
       "  '01.01.03.01',\n",
       "  '01.01.03.01.01',\n",
       "  '01.01.03.01.02',\n",
       "  '01.01.03.01.03',\n",
       "  '01.01.03.02',\n",
       "  '01.01.04',\n",
       "  '01.01.04.01',\n",
       "  '01.01.04.02',\n",
       "  '01.01.04.03',\n",
       "  '01.01.05',\n",
       "  '01.01.06',\n",
       "  '01.01.07',\n",
       "  '01.01.09',\n",
       "  '01.02',\n",
       "  '01.02.01',\n",
       "  '01.02.01.02',\n",
       "  '01.02.01.03',\n",
       "  '01.02.01.04',\n",
       "  '01.02.01.05',\n",
       "  '01.02.01.06',\n",
       "  '01.02.01.07',\n",
       "  '01.02.01.08',\n",
       "  '01.02.01.09',\n",
       "  '01.02.02',\n",
       "  '01.02.02.01',\n",
       "  '01.02.02.01.01',\n",
       "  '01.02.02.01.02',\n",
       "  '01.02.02.01.03',\n",
       "  '01.02.02.02',\n",
       "  '01.02.03',\n",
       "  '01.02.03.01',\n",
       "  '01.02.03.02',\n",
       "  '01.02.04',\n",
       "  '01.02.04.01',\n",
       "  '01.02.04.01.01',\n",
       "  '01.02.04.01.02',\n",
       "  '01.02.04.01.03',\n",
       "  '01.02.04.02',\n",
       "  '01.02.04.02.01',\n",
       "  '02',\n",
       "  '02.01',\n",
       "  '02.01.01.01',\n",
       "  '02.01.01.02',\n",
       "  '02.01.02',\n",
       "  '02.01.02.01',\n",
       "  '02.01.02.02',\n",
       "  '02.01.03',\n",
       "  '02.01.03.01',\n",
       "  '02.01.03.01.01',\n",
       "  '02.01.03.01.02',\n",
       "  '02.01.03.01.03',\n",
       "  '02.01.03.02',\n",
       "  '02.01.03.03',\n",
       "  '02.01.04',\n",
       "  '02.01.04.01',\n",
       "  '02.01.04.01.01',\n",
       "  '02.01.04.01.02',\n",
       "  '02.01.04.02',\n",
       "  '02.01.04.03',\n",
       "  '02.01.05',\n",
       "  '02.01.05.01',\n",
       "  '02.01.05.01.01',\n",
       "  '02.01.05.01.03',\n",
       "  '02.01.05.01.04',\n",
       "  '02.01.05.02',\n",
       "  '02.01.05.02.01',\n",
       "  '02.01.05.02.02',\n",
       "  '02.01.05.02.03',\n",
       "  '02.01.05.02.04',\n",
       "  '02.01.05.02.09',\n",
       "  '02.01.06',\n",
       "  '02.01.06.01',\n",
       "  '02.01.06.01.01',\n",
       "  '02.01.06.01.02',\n",
       "  '02.01.06.01.03',\n",
       "  '02.01.06.01.04',\n",
       "  '02.01.06.02',\n",
       "  '02.01.06.02.01',\n",
       "  '02.01.06.02.02',\n",
       "  '02.01.06.02.03',\n",
       "  '02.02',\n",
       "  '02.02.01',\n",
       "  '02.02.01.01',\n",
       "  '02.02.01.01.01',\n",
       "  '02.02.01.01.02',\n",
       "  '02.02.01.02',\n",
       "  '02.02.01.03',\n",
       "  '02.02.02',\n",
       "  '02.02.02.01.04',\n",
       "  '02.02.03',\n",
       "  '02.02.04',\n",
       "  '02.02.04.01',\n",
       "  '02.03',\n",
       "  '02.03.01',\n",
       "  '02.03.01.01',\n",
       "  '02.03.01.02',\n",
       "  '02.03.02',\n",
       "  '02.03.02.01',\n",
       "  '02.03.02.02',\n",
       "  '02.03.02.09',\n",
       "  '02.03.03',\n",
       "  '02.03.04',\n",
       "  '02.03.04.01',\n",
       "  '02.03.04.02',\n",
       "  '02.03.04.03',\n",
       "  '02.03.04.09',\n",
       "  '02.03.05',\n",
       "  '02.03.06',\n",
       "  '02.03.06.01',\n",
       "  '02.03.06.02',\n",
       "  '02.03.06.09',\n",
       "  '02.03.07',\n",
       "  '02.03.08',\n",
       "  '02.03.09',\n",
       "  '03.01',\n",
       "  '03.02',\n",
       "  '03.03',\n",
       "  '03.04',\n",
       "  '03.04.01',\n",
       "  '03.04.01.01',\n",
       "  '03.05',\n",
       "  '03.06',\n",
       "  '03.07',\n",
       "  '03.08',\n",
       "  '03.11',\n",
       "  '03.11.01',\n",
       "  '03.11.02',\n",
       "  '06.01',\n",
       "  '06.02',\n",
       "  '06.03',\n",
       "  '07.01',\n",
       "  '07.01.01',\n",
       "  '07.01.02',\n",
       "  '07.01.03',\n",
       "  '07.01.04',\n",
       "  '07.02',\n",
       "  '07.02.01',\n",
       "  '07.02.02',\n",
       "  '07.02.03',\n",
       "  '07.02.04',\n",
       "  '07.03',\n",
       "  '07.04',\n",
       "  '07.04.01',\n",
       "  '07.04.02',\n",
       "  '07.05',\n",
       "  '07.06',\n",
       "  '07.06.01',\n",
       "  '07.06.02',\n",
       "  '07.06.03',\n",
       "  '07.06.03.01',\n",
       "  '07.06.03.02',\n",
       "  '07.07',\n",
       "  '07.08',\n",
       "  '07.08.01',\n",
       "  '07.08.01.01',\n",
       "  '07.08.01.02',\n",
       "  '07.08.01.03',\n",
       "  '07.08.01.04',\n",
       "  '07.08.02',\n",
       "  '07.08.02.01',\n",
       "  '07.08.02.02',\n",
       "  '07.08.02.03',\n",
       "  '07.08.03',\n",
       "  '07.08.03.01',\n",
       "  '07.08.03.02',\n",
       "  '07.08.03.03',\n",
       "  '07.08.04',\n",
       "  '07.08.04.01',\n",
       "  '07.08.04.02',\n",
       "  '07.08.04.03',\n",
       "  '07.08.04.04',\n",
       "  '07.08.05.01',\n",
       "  '07.08.05.02',\n",
       "  '07.08.05.03',\n",
       "  '07.08.05.04',\n",
       "  '07.08.05.09'],\n",
       " 'description': ['Ajustes Acumulados de Conversão',\n",
       "  'Ajustes Patrimoniais',\n",
       "  'Ajustes de Avaliação Patrimonial',\n",
       "  'Aluguéis',\n",
       "  'Aplicações Financeiras de Curto Prazo',\n",
       "  'Aplicações Líquidas de Curto Prazo',\n",
       "  'Aplicações a Valor Justo de Curto Prazo',\n",
       "  'Aplicações a Valor Justo de Longo Prazo',\n",
       "  'Aplicações ao Custo Amortizado de Curto Prazo',\n",
       "  'Ativo Circulante de Curto Prazo',\n",
       "  'Ativo Não Circulante de Longo Prazo',\n",
       "  'Ativo Realizável a Longo Prazo',\n",
       "  'Ativo Total',\n",
       "  'Ativos Biológicos de Curto Prazo',\n",
       "  'Ativos Biológicos de Longo Prazo',\n",
       "  'Atribuído a Sócios Não Controladores',\n",
       "  'Atribuído a Sócios da Empresa Controladora',\n",
       "  'Ações ON Ordinárias',\n",
       "  'Ações PN Preferenciais',\n",
       "  'Ações, Remuneração e Opções',\n",
       "  'Benefícios',\n",
       "  'Caixa de Financiamento',\n",
       "  'Caixa de Investimento',\n",
       "  'Caixa de Operações (Operacional)',\n",
       "  'Caixa e Bancos de Curto Prazo',\n",
       "  'Caixa e Equivalentes de Caixa de Curto Prazo',\n",
       "  'Capital Social',\n",
       "  'Capital Social Realizado',\n",
       "  'Carteira de Clientes',\n",
       "  'Clientes',\n",
       "  'Contas a Receber de Curto Prazo',\n",
       "  'Contas a Receber de Longo Prazo',\n",
       "  'Contas de Clientes de Curto Prazo',\n",
       "  'Créditos com Partes Relacionadas de Longo Prazo',\n",
       "  'Créditos de Liquidação Duvidosa',\n",
       "  'Custo dos Bens e/ou Serviços Vendidos',\n",
       "  'Custos Prods., Mercs. e Servs. Vendidos',\n",
       "  'Debêntures',\n",
       "  'Depreciação, Amortização e Exaustão',\n",
       "  'Derivativos e Participações',\n",
       "  'Despesas Antecipadas de Curto Prazo',\n",
       "  'Despesas Antecipadas de Longo Prazo',\n",
       "  'Despesas Comerciais',\n",
       "  'Despesas Operacionais',\n",
       "  'Despesas/Receitas Operacionais',\n",
       "  'Direito de Uso em Arrendamento',\n",
       "  'Distribuição do Valor Adicionado',\n",
       "  'Dividendos',\n",
       "  'Dividendos e Ações',\n",
       "  'Dividendos e Ações em Tesouraria',\n",
       "  'Débitos com Coligadas',\n",
       "  'Débitos com Controladores',\n",
       "  'Débitos com Outras Partes Relacionadas',\n",
       "  'Em Moeda Estrangeira',\n",
       "  'Em Moeda Nacional',\n",
       "  'Em Tesouraria Ações ON Ordinárias',\n",
       "  'Em Tesouraria Ações PN Preferenciais',\n",
       "  'Empréstimos e Financiamentos',\n",
       "  'Empréstimos e Financiamentos de Curto Prazo',\n",
       "  'Empréstimos e Financiamentos de Longo Prazo',\n",
       "  'Estaduais',\n",
       "  'Estoques de Curto Prazo',\n",
       "  'Estoques de Longo Prazo',\n",
       "  'Estoques de Material de Consumo de Curto Prazo',\n",
       "  'Estoques de Material para Revenda de Curto Prazo',\n",
       "  'Estoques de Outros Itens de Curto Prazo',\n",
       "  'F.G.T.S.',\n",
       "  'Federais',\n",
       "  'Financiamento por Arrendamento Financeiro',\n",
       "  'Fornecedores Estrangeiros',\n",
       "  'Fornecedores Nacionais',\n",
       "  'Fornecedores de Curto Prazo',\n",
       "  'Gastos na emissão de ações',\n",
       "  'Goodwill',\n",
       "  'Imobilizado',\n",
       "  'Imobilizado em Operação',\n",
       "  'Imposto de Renda e Contribuição Social Diferidos',\n",
       "  'Imposto de Renda e Contribuição Social a Pagar',\n",
       "  'Imposto de Renda e Contribuição Social sobre o Lucro',\n",
       "  'Impostos, Taxas e Contribuições',\n",
       "  'Insumos Adquiridos de Terceiros',\n",
       "  'Intangíveis',\n",
       "  'Intangível',\n",
       "  'Investimento Social',\n",
       "  'Investimentos',\n",
       "  'Juros',\n",
       "  'Juros sobre o Capital Próprio',\n",
       "  'Lucro do Período',\n",
       "  'Lucros Retidos',\n",
       "  'Lucros Retidos / Prejuízo do Período',\n",
       "  'Lucros/Prejuízos Acumulados',\n",
       "  'Marcas e Patentes',\n",
       "  'Materiais, Energia, Servs. de Terceiros e Outros',\n",
       "  'Municipais',\n",
       "  'Obrigações Fiscais Estaduais',\n",
       "  'Obrigações Fiscais Federais',\n",
       "  'Obrigações Fiscais Municipais',\n",
       "  'Obrigações Fiscais de Curto Prazo',\n",
       "  'Obrigações Sociais',\n",
       "  'Obrigações Trabalhistas',\n",
       "  'Obrigações Tributárias e Autorizações',\n",
       "  'Outras',\n",
       "  'Outras Contas de Curto Prazo',\n",
       "  'Outras Obrigações Fiscais Federais',\n",
       "  'Outras Obrigações de Curto Prazo',\n",
       "  'Outras Provisões',\n",
       "  'Outras Receitas',\n",
       "  'Outros',\n",
       "  'Outros Ativos Circulantes de Curto Prazo',\n",
       "  'Outros Ativos Circulantes de Longo Prazo',\n",
       "  'Outros Resultados Abrangentes',\n",
       "  'Part. Não Controladores nos Lucros Retidos',\n",
       "  'Participação Minoritária',\n",
       "  'Participação dos Acionistas Não Controladores',\n",
       "  'Participações Societárias',\n",
       "  'Participações em Coligadas',\n",
       "  'Participações em Controladas',\n",
       "  'Passivo Circulante de Curto Prazo',\n",
       "  'Passivo Não Circulante de Longo Prazo',\n",
       "  'Passivo Total',\n",
       "  'Passivos com Partes Relacionadas',\n",
       "  'Passivos com Partes Relacionadas de Longo Prazo',\n",
       "  'Patrimônio Líquido',\n",
       "  'Perda/Recuperação de Valores Ativos',\n",
       "  'Perdas e Aquisições com Não Controladores',\n",
       "  'Pessoal',\n",
       "  'Propriedades para Investimento',\n",
       "  'Provisão/Reversão de Créds. Liquidação Duvidosa',\n",
       "  'Provisões Cíveis',\n",
       "  'Provisões Fiscais',\n",
       "  'Provisões Fiscais Previdenciárias Trabalhistas e Cíveis',\n",
       "  'Provisões Judiciais',\n",
       "  'Provisões Previdenciárias e Trabalhistas',\n",
       "  'Provisões de Curto Prazo',\n",
       "  'Provisões de Longo Prazo',\n",
       "  'Provisões para Benefícios a Empregados',\n",
       "  'Provisões para Garantias',\n",
       "  'Provisões para Passivos Ambientais e de Desativação',\n",
       "  'Provisões para Reestruturação',\n",
       "  'Provisões trabalhistas e cíveis, líquidas',\n",
       "  'Receita de Venda de Bens e/ou Serviços',\n",
       "  'Receitas',\n",
       "  'Receitas Financeiras',\n",
       "  'Receitas refs. à Construção de Ativos Próprios',\n",
       "  'Remuneração Direta',\n",
       "  'Remuneração de Capitais Próprios',\n",
       "  'Remuneração de Capitais de Terceiros',\n",
       "  'Reservas Legais e Estatutárias',\n",
       "  'Reservas de Capital',\n",
       "  'Reservas de Lucros',\n",
       "  'Reservas de Reavaliação',\n",
       "  'Resultado Antes do Resultado Financeiro e dos Tributos',\n",
       "  'Resultado Antes dos Tributos sobre o Lucro',\n",
       "  'Resultado Bruto',\n",
       "  'Resultado Financeiro',\n",
       "  'Resultado de Equivalência Patrimonial',\n",
       "  'Retenção de Lucros e Incentivos Fiscais',\n",
       "  'Retenções',\n",
       "  'Softwares',\n",
       "  'Telecomunicações e Consignações',\n",
       "  'Tributos Parcelados',\n",
       "  'Tributos a Recuperar de Curto Prazo',\n",
       "  'Tributos a Recuperar de Longo Prazo',\n",
       "  'Valor Adicionado Bruto',\n",
       "  'Valor Adicionado Líquido Produzido',\n",
       "  'Valor Adicionado Total a Distribuir',\n",
       "  'Vendas de Mercadorias, Produtos e Serviços',\n",
       "  'Vlr Adicionado Recebido em Transferência',\n",
       "  'Ágio e Reserva Especial']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store unique values\n",
    "uv = {}\n",
    "for col in df.columns:\n",
    "    if col not in [\"nsd\", \"value\"]:\n",
    "        uv[col] = sorted(df[col].unique().tolist())\n",
    "uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_series(\n",
    "    company_name,\n",
    "    account,\n",
    "    start_date=None,\n",
    "    end_date=None,\n",
    "    window=4,\n",
    "    std_dev=2,\n",
    "    normalize=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a time series of a financial metric for a given company, with Bollinger Bands and custom blue color scheme.\n",
    "\n",
    "    Args:\n",
    "    - company_name: Name of the company.\n",
    "    - account: The financial account to be plotted.\n",
    "    - start_date: Run date for filtering the data (optional).\n",
    "    - end_date: End date for filtering the data (optional).\n",
    "    - window: The window size for the moving average (default is 4).\n",
    "    - std_dev: The number of standard deviations for the Bollinger Bands (default is 2).\n",
    "    \"\"\"\n",
    "    # Define blue color scheme\n",
    "    color_blue = {\n",
    "        \"main\": \"blue\",\n",
    "        \"mma\": \"lightblue\",\n",
    "        \"bands\": \"lightblue\",\n",
    "        \"fill\": \"rgba(173, 216, 230, 0.2)\",\n",
    "        \"extra_bands\": \"lightgray\",\n",
    "        \"extra_fill\": \"rgba(200, 200, 200, 0.2)\",\n",
    "    }\n",
    "\n",
    "    # Try 'DFs Consolidadas' first\n",
    "    if (df[\"type\"] == \"DFs Consolidadas\").any():\n",
    "        df_type = \"DFs Consolidadas\"\n",
    "    else:\n",
    "        df_type = \"DFs Individuais\"\n",
    "\n",
    "    # Filter data\n",
    "    data = df[\n",
    "        (df[\"company_name\"] == company_name)\n",
    "        & (df[\"account\"] == account)\n",
    "        & (df[\"type\"] == df_type)\n",
    "    ]\n",
    "\n",
    "    # Apply date filters if provided\n",
    "    if start_date:\n",
    "        data = data[data[\"quarter\"] >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        data = data[data[\"quarter\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "    if data.empty:\n",
    "        print(\"No data available for the given filters, check parameters.\")\n",
    "        return\n",
    "\n",
    "    if normalize == True:\n",
    "        # Drop the first row if its value is zero\n",
    "        if data[\"value\"].iloc[0] == 0:\n",
    "            data = data.iloc[1:].copy()\n",
    "\n",
    "        # Get the first non-zero value\n",
    "        first_non_zero = data[\"value\"].iloc[0]\n",
    "\n",
    "        # Normalize the values by dividing by the first non-zero value\n",
    "        data[\"value\"] = data[\"value\"] / first_non_zero\n",
    "\n",
    "        # Scale the values so that the maximum is 100\n",
    "        max_value = data[\"value\"].max()\n",
    "        data[\"value\"] = (data[\"value\"] / max_value) * 100\n",
    "\n",
    "    # Sort data by date\n",
    "    data = data.sort_values(\"quarter\")\n",
    "\n",
    "    # Calculate the moving average (Middle Band)\n",
    "    data[\"mma\"] = data[\"value\"].rolling(window=window).mean()\n",
    "\n",
    "    # Calculate the rolling standard deviation\n",
    "    data[\"std_dev\"] = data[\"value\"].rolling(window=window).std()\n",
    "\n",
    "    # Calculate upper and lower Bollinger Bands with std_dev multiplier\n",
    "    data[\"upper_band\"] = data[\"mma\"] + std_dev * data[\"std_dev\"]\n",
    "    data[\"lower_band\"] = data[\"mma\"] - std_dev * data[\"std_dev\"]\n",
    "\n",
    "    # Calculate extra upper and lower bands using std_dev * 1.5\n",
    "    extra_std_dev = std_dev * 1.5\n",
    "    data[\"upper_band_extra\"] = data[\"mma\"] + extra_std_dev * data[\"std_dev\"]\n",
    "    data[\"lower_band_extra\"] = data[\"mma\"] - extra_std_dev * data[\"std_dev\"]\n",
    "\n",
    "    # Set description to the first non-null description value in the filtered data\n",
    "    description = (\n",
    "        data[\"description\"].dropna().iloc[0]\n",
    "        if \"description\" in data.columns and not data[\"description\"].isna().all()\n",
    "        else account\n",
    "    )\n",
    "\n",
    "    # Create line plot with original values\n",
    "    fig = px.line(\n",
    "        data,\n",
    "        x=\"quarter\",\n",
    "        y=\"value\",\n",
    "        title=f\"{account} - {description} with Bollinger Bands for {company_name} ({df_type})\",\n",
    "        labels={\"quarter\": \"Quarter\", \"value\": description},\n",
    "        template=\"plotly_white\",\n",
    "    )\n",
    "\n",
    "    # Add main line for the data\n",
    "    fig.update_traces(\n",
    "        line=dict(color=color_blue[\"main\"]), name=\"Original Data\", showlegend=False\n",
    "    )\n",
    "\n",
    "    # Add moving average (MMA) as a dashed light blue line\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"mma\"],\n",
    "        mode=\"lines\",\n",
    "        name=f\"Middle Band (window={window})\",\n",
    "        line=dict(color=color_blue[\"mma\"], dash=\"dash\"),\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Add upper and lower Bollinger Bands (std_dev * 2) and group them\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"upper_band\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Upper Band (std_dev * 2)\",\n",
    "        line=dict(dash=\"solid\", color=color_blue[\"bands\"]),\n",
    "        legendgroup=\"Bands (std_dev * 2)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"lower_band\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Lower Band (std_dev * 2)\",\n",
    "        line=dict(dash=\"solid\", color=color_blue[\"bands\"]),\n",
    "        legendgroup=\"Bands (std_dev * 2)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Fill the area between the upper and lower bands (std_dev * 2)\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"upper_band\"],\n",
    "        fill=None,\n",
    "        mode=\"lines\",\n",
    "        name=\"Upper Band Fill (std_dev * 2)\",\n",
    "        line=dict(color=\"rgba(0,0,0,0)\"),\n",
    "        showlegend=False,\n",
    "        legendgroup=\"Bands (std_dev * 2)\",\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"lower_band\"],\n",
    "        fill=\"tonexty\",\n",
    "        mode=\"lines\",\n",
    "        name=\"Lower Band Fill (std_dev * 2)\",\n",
    "        line=dict(color=\"rgba(0,0,0,0)\"),\n",
    "        fillcolor=color_blue[\"fill\"],\n",
    "        showlegend=False,\n",
    "        legendgroup=\"Bands (std_dev * 2)\",\n",
    "    )\n",
    "\n",
    "    # Add extra upper and lower Bollinger Bands (std_dev * 1.5) and group them\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"upper_band_extra\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Upper Band (std_dev * 1.5)\",\n",
    "        line=dict(dash=\"dot\", color=color_blue[\"extra_bands\"]),\n",
    "        legendgroup=\"Bands (std_dev * 1.5)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"lower_band_extra\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Lower Band (std_dev * 1.5)\",\n",
    "        line=dict(dash=\"dot\", color=color_blue[\"extra_bands\"]),\n",
    "        legendgroup=\"Bands (std_dev * 1.5)\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "\n",
    "    # Fill the area between the extra upper and lower bands (std_dev * 1.5)\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"upper_band_extra\"],\n",
    "        fill=None,\n",
    "        mode=\"lines\",\n",
    "        name=\"Upper Band Extra Fill (std_dev * 1.5)\",\n",
    "        line=dict(color=\"rgba(0,0,0,0)\"),\n",
    "        showlegend=False,\n",
    "        legendgroup=\"Bands (std_dev * 1.5)\",\n",
    "    )\n",
    "\n",
    "    fig.add_scatter(\n",
    "        x=data[\"quarter\"],\n",
    "        y=data[\"lower_band_extra\"],\n",
    "        fill=\"tonexty\",\n",
    "        mode=\"lines\",\n",
    "        name=\"Lower Band Extra Fill (std_dev * 1.5)\",\n",
    "        line=dict(color=\"rgba(0,0,0,0)\"),\n",
    "        fillcolor=color_blue[\"extra_fill\"],\n",
    "        showlegend=False,\n",
    "        legendgroup=\"Bands (std_dev * 1.5)\",\n",
    "    )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(xaxis_title=\"Quarter\", yaxis_title=description)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = plot_series(\n",
    "    company_name=uv[\"company_name\"][7],  # Change to your desired company\n",
    "    account=\"01.01\",\n",
    "    # start_date='2015-01-01',\n",
    "    # end_date='2023-06-30',\n",
    "    window=4,\n",
    "    normalize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(\n",
    "    company_name, accounts, start_date=None, end_date=None, plot_type=\"stacked\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a stacked, overlapping, line-only, 100% stacked, or normalized stacked area chart of financial metrics for multiple accounts of a given company.\n",
    "\n",
    "    Args:\n",
    "    - company_name: Name of the company.\n",
    "    - accounts: List of financial accounts to be plotted.\n",
    "    - start_date: Run date for filtering the data (optional).\n",
    "    - end_date: End date for filtering the data (optional).\n",
    "    - plot_type: Determines the type of plot: \"stacked\", \"overlapping\", \"lines\", \"100_stacked\", or \"normalized_stacked\".\n",
    "    \"\"\"\n",
    "    # Filter and combine data for all accounts\n",
    "    filtered_data = pd.DataFrame()\n",
    "\n",
    "    for account in accounts:\n",
    "        # Try 'DFs Consolidadas' first\n",
    "        if (df[\"type\"] == \"DFs Consolidadas\").any():\n",
    "            df_type = \"DFs Consolidadas\"\n",
    "        else:\n",
    "            df_type = \"DFs Individuais\"\n",
    "\n",
    "        # Filter data for the current account\n",
    "        data = df[\n",
    "            (df[\"company_name\"] == company_name)\n",
    "            & (df[\"account\"] == account)\n",
    "            & (df[\"type\"] == df_type)\n",
    "        ]\n",
    "\n",
    "        # Apply date filters if provided\n",
    "        if start_date:\n",
    "            data = data[data[\"quarter\"] >= pd.to_datetime(start_date)]\n",
    "        if end_date:\n",
    "            data = data[data[\"quarter\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"No data available for account {account}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Apply normalization only when plot_type is \"normalized_stacked\"\n",
    "        if plot_type == \"normalized_stacked\":\n",
    "            # Drop the first row if its value is zero\n",
    "            if data[\"value\"].iloc[0] == 0:\n",
    "                data = data.iloc[1:].copy()\n",
    "\n",
    "            # Get the first non-zero value and normalize all data by that value\n",
    "            first_non_zero_value = data[\"value\"][data[\"value\"] != 0].iloc[0]\n",
    "\n",
    "            # Normalize to ensure the first non-zero value is 1\n",
    "            data.loc[:, \"value\"] = data[\"value\"] / first_non_zero_value\n",
    "\n",
    "        # Sort data by date\n",
    "        data = data.sort_values(\"quarter\")\n",
    "\n",
    "        # Add the account as a column for identifying each account\n",
    "        data[\"account\"] = account\n",
    "\n",
    "        # Append to the cumulative data\n",
    "        filtered_data = pd.concat([filtered_data, data])\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data available for the given filters, check parameters.\")\n",
    "        return\n",
    "\n",
    "    # Determine the Y-axis label\n",
    "    y_axis_title = \"Value\"\n",
    "\n",
    "    # Plot logic for different plot types\n",
    "    if plot_type == \"stacked\":\n",
    "        # Stacked area plot with raw values\n",
    "        fig = px.area(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Stacked Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    elif plot_type == \"overlapping\":\n",
    "        # Overlapping area plot (using filled line plots to avoid stacking)\n",
    "        fig = px.line(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Overlapping Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "        # Add filled areas to create the overlapping effect\n",
    "        for account in accounts:\n",
    "            account_data = filtered_data[filtered_data[\"account\"] == account]\n",
    "            fig.add_scatter(\n",
    "                x=account_data[\"quarter\"],\n",
    "                y=account_data[\"value\"],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=0.5),\n",
    "                fill=\"tozeroy\",\n",
    "                name=account,\n",
    "                legendgroup=account,  # Group line and area under the same legend\n",
    "                showlegend=False,  # Hide the second entry for the filled area\n",
    "            )\n",
    "\n",
    "    elif plot_type == \"lines\":\n",
    "        # Line-only plot with no filling\n",
    "        fig = px.line(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Line-Only Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    elif plot_type == \"100_stacked\":\n",
    "        # 100% stacked area plot (scaled to show percentages)\n",
    "        filtered_data[\"total_per_quarter\"] = filtered_data.groupby(\"quarter\")[\n",
    "            \"value\"\n",
    "        ].transform(\"sum\")\n",
    "        filtered_data[\"value\"] = (\n",
    "            filtered_data[\"value\"] / filtered_data[\"total_per_quarter\"]\n",
    "        ) * 100\n",
    "        y_axis_title = \"Percentage Contribution (%)\"\n",
    "\n",
    "        fig = px.area(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"100% Stacked Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    elif plot_type == \"normalized_stacked\":\n",
    "        # Normalized stacked area plot (no percentage, just normalized values for each account)\n",
    "        y_axis_title = \"Normalized Value\"\n",
    "\n",
    "        fig = px.area(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Normalized Stacked Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(xaxis_title=\"Quarter\", yaxis_title=y_axis_title, showlegend=True)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     - plot_type: Determines the type of plot: \"stacked\", \"lines\", \"overlapping\", \"100_stacked\", or \"normalized_stacked\".\n",
    "# Example usage: Line-only plot\n",
    "data = plot_time_series(\n",
    "    company_name=uv[\"company_name\"][7],\n",
    "    accounts=[\n",
    "        \"01.01.01\",\n",
    "        \"01.01.02\",\n",
    "        \"01.01.03\",\n",
    "        \"01.01.04\",\n",
    "    ],\n",
    "    plot_type=\"stacked\",  # Line-only plot\n",
    "    start_date=\"2013-12-31\",\n",
    ")\n",
    "\n",
    "# Example usage: Line-only plot\n",
    "data = plot_time_series(\n",
    "    company_name=uv[\"company_name\"][7],\n",
    "    accounts=[\n",
    "        \"01.01.01\",\n",
    "        \"01.01.02\",\n",
    "        \"01.01.03\",\n",
    "        \"01.01.04\",\n",
    "    ],\n",
    "    plot_type=\"100_stacked\",  # Line-only plot\n",
    "    start_date=\"2013-12-31\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(\n",
    "    company_name, accounts, start_date=None, end_date=None, plot_type=\"stacked\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a stacked, overlapping, line-only, 100% stacked, or normalized stacked area chart of financial metrics for multiple accounts of a given company.\n",
    "\n",
    "    Args:\n",
    "    - company_name: Name of the company.\n",
    "    - accounts: List of financial accounts to be plotted.\n",
    "    - start_date: Run date for filtering the data (optional).\n",
    "    - end_date: End date for filtering the data (optional).\n",
    "    - plot_type: Determines the type of plot: \"stacked\", \"overlapping\", \"lines\", \"100_stacked\", or \"normalized_stacked\".\n",
    "    \"\"\"\n",
    "    # Filter and combine data for all accounts\n",
    "    filtered_data = pd.DataFrame()\n",
    "\n",
    "    for account in accounts:\n",
    "        # Try 'DFs Consolidadas' first\n",
    "        if (df[\"type\"] == \"DFs Consolidadas\").any():\n",
    "            df_type = \"DFs Consolidadas\"\n",
    "        else:\n",
    "            df_type = \"DFs Individuais\"\n",
    "\n",
    "        # Filter data for the current account\n",
    "        data = df[\n",
    "            (df[\"company_name\"] == company_name)\n",
    "            & (df[\"account\"] == account)\n",
    "            & (df[\"type\"] == df_type)\n",
    "        ]\n",
    "\n",
    "        # Apply date filters if provided\n",
    "        if start_date:\n",
    "            data = data[data[\"quarter\"] >= pd.to_datetime(start_date)]\n",
    "        if end_date:\n",
    "            data = data[data[\"quarter\"] <= pd.to_datetime(end_date)]\n",
    "\n",
    "        if data.empty:\n",
    "            print(f\"No data available for account {account}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Apply normalization only when plot_type is \"normalized_stacked\"\n",
    "        if plot_type == \"normalized_stacked\":\n",
    "            # Drop the first row if its value is zero\n",
    "            if data[\"value\"].iloc[0] == 0:\n",
    "                data = data.iloc[1:].copy()\n",
    "\n",
    "            # Get the first non-zero value and normalize all data by that value\n",
    "            first_non_zero_value = data[\"value\"][data[\"value\"] != 0].iloc[0]\n",
    "\n",
    "            # Normalize to ensure the first non-zero value is 1\n",
    "            data.loc[:, \"value\"] = data[\"value\"] / first_non_zero_value\n",
    "\n",
    "        # Sort data by date\n",
    "        data = data.sort_values(\"quarter\")\n",
    "\n",
    "        # Add the account as a column for identifying each account\n",
    "        data[\"account\"] = account\n",
    "\n",
    "        # Append to the cumulative data\n",
    "        filtered_data = pd.concat([filtered_data, data])\n",
    "\n",
    "    if filtered_data.empty:\n",
    "        print(\"No data available for the given filters, check parameters.\")\n",
    "        return\n",
    "\n",
    "    # Determine the Y-axis label\n",
    "    y_axis_title = \"Value\"\n",
    "\n",
    "    # Plot logic for different plot types\n",
    "    if plot_type == \"stacked\":\n",
    "        # Stacked area plot with raw values\n",
    "        fig = px.area(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Stacked Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    elif plot_type == \"overlapping\":\n",
    "        # Overlapping area plot (using filled line plots to avoid stacking)\n",
    "        fig = px.line(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Overlapping Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "        # Add filled areas to create the overlapping effect\n",
    "        for account in accounts:\n",
    "            account_data = filtered_data[filtered_data[\"account\"] == account]\n",
    "            fig.add_scatter(\n",
    "                x=account_data[\"quarter\"],\n",
    "                y=account_data[\"value\"],\n",
    "                mode=\"lines\",\n",
    "                line=dict(width=0.5),\n",
    "                fill=\"tozeroy\",\n",
    "                name=account,\n",
    "                legendgroup=account,  # Group line and area under the same legend\n",
    "                showlegend=False,  # Hide the second entry for the filled area\n",
    "            )\n",
    "\n",
    "    elif plot_type == \"lines\":\n",
    "        # Line-only plot with no filling\n",
    "        fig = px.line(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Line-Only Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    elif plot_type == \"100_stacked\":\n",
    "        # 100% stacked area plot (scaled to show percentages)\n",
    "        filtered_data[\"total_per_quarter\"] = filtered_data.groupby(\"quarter\")[\n",
    "            \"value\"\n",
    "        ].transform(\"sum\")\n",
    "        filtered_data[\"value\"] = (\n",
    "            filtered_data[\"value\"] / filtered_data[\"total_per_quarter\"]\n",
    "        ) * 100\n",
    "        y_axis_title = \"Percentage Contribution (%)\"\n",
    "\n",
    "        fig = px.area(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"100% Stacked Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    elif plot_type == \"normalized_stacked\":\n",
    "        # Normalized stacked area plot (no percentage, just normalized values for each account)\n",
    "        y_axis_title = \"Normalized Value\"\n",
    "\n",
    "        fig = px.area(\n",
    "            filtered_data,\n",
    "            x=\"quarter\",\n",
    "            y=\"value\",\n",
    "            color=\"account\",\n",
    "            title=f\"Normalized Stacked Area Plot of Accounts for {company_name}\",\n",
    "            labels={\"quarter\": \"Quarter\", \"value\": y_axis_title},\n",
    "            template=\"plotly_white\",\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(xaxis_title=\"Quarter\", yaxis_title=y_axis_title, showlegend=True)\n",
    "\n",
    "    return fig  # Return the figure, not the DataFrame\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Initialize a subplot figure with 2 rows and 1 column\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1, subplot_titles=(\"Stacked Plot\", \"100% Stacked Plot\")\n",
    ")\n",
    "\n",
    "# Call plot_time_series for the stacked plot and add to the first subplot (row 1)\n",
    "fig_stacked = plot_time_series(\n",
    "    company_name=uv[\"company_name\"][7],\n",
    "    accounts=[\"01.01.01\", \"01.01.02\", \"01.01.03\", \"01.01.04\"],\n",
    "    plot_type=\"stacked\",\n",
    "    start_date=\"2013-12-31\",\n",
    ")\n",
    "\n",
    "# Add the traces from the stacked plot to the first subplot\n",
    "for trace in fig_stacked[\"data\"]:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "# Call plot_time_series for the 100% stacked plot and add to the second subplot (row 2)\n",
    "fig_100_stacked = plot_time_series(\n",
    "    company_name=uv[\"company_name\"][7],\n",
    "    accounts=[\"01.01.01\", \"01.01.02\", \"01.01.03\", \"01.01.04\"],\n",
    "    plot_type=\"100_stacked\",\n",
    "    start_date=\"2013-12-31\",\n",
    ")\n",
    "\n",
    "# Add the traces from the 100% stacked plot to the second subplot\n",
    "for trace in fig_100_stacked[\"data\"]:\n",
    "    fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "# Update the layout for the entire figure\n",
    "fig.update_layout(\n",
    "    title_text=\"Comparison of Stacked and 100% Stacked Plots\",\n",
    "    height=800,\n",
    "    showlegend=False,  # Hide the legend since it might overlap\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_company_comparison(\n",
    "    df, companies, account, start_date=None, end_date=None, plot_type=\"lines\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare a financial metric (account) across multiple companies, filtered by 'df_type',\n",
    "    and display the average of the companies.\n",
    "\n",
    "    Args:\n",
    "    - df: DataFrame containing the financial data.\n",
    "    - companies: List of company names to compare.\n",
    "    - account: The financial account to be plotted (e.g., '03.11 - Lucro do Período').\n",
    "    - start_date: Run date for filtering the data (optional).\n",
    "    - end_date: End date for filtering the data (optional).\n",
    "    - plot_type: Determines whether to plot 'lines' or 'normalized'.\n",
    "    \"\"\"\n",
    "    # Try 'DFs Consolidadas' first\n",
    "    if (df[\"type\"] == \"DFs Consolidadas\").any():\n",
    "        df_type = \"DFs Consolidadas\"\n",
    "    else:\n",
    "        df_type = \"DFs Individuais\"\n",
    "\n",
    "    # Filter data for the specified companies, account, and df_type\n",
    "    data = df[\n",
    "        (df[\"company_name\"].isin(companies))\n",
    "        & (df[\"account\"] == account)\n",
    "        & (df[\"type\"] == df_type)\n",
    "    ].copy()  # Make a deep copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Apply start and end date filters if provided\n",
    "    if start_date:\n",
    "        data = data[\n",
    "            data[\"quarter\"] >= pd.to_datetime(start_date)\n",
    "        ].copy()  # Copy after filtering\n",
    "    if end_date:\n",
    "        data = data[\n",
    "            data[\"quarter\"] <= pd.to_datetime(end_date)\n",
    "        ].copy()  # Copy after filtering\n",
    "\n",
    "    if data.empty:\n",
    "        print(\"No data available for the given filters.\")\n",
    "        return\n",
    "\n",
    "    # Get the description dynamically from the DataFrame based on the 'account' field\n",
    "    description = (\n",
    "        data[\"description\"].dropna().iloc[0]\n",
    "        if \"description\" in data.columns and not data[\"description\"].isna().all()\n",
    "        else account\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add line plot for each company (no markers)\n",
    "    for company in companies:\n",
    "        company_data = (\n",
    "            data[data[\"company_name\"] == company].sort_values(\"quarter\").copy()\n",
    "        )  # Avoid modifying the original DataFrame\n",
    "\n",
    "        if not company_data.empty:\n",
    "            if plot_type == \"normalized\":\n",
    "                # Try to get the first non-zero value for normalization\n",
    "                non_zero_values = company_data[\"value\"][company_data[\"value\"] != 0]\n",
    "\n",
    "                if not non_zero_values.empty:\n",
    "                    first_non_zero_value = non_zero_values.iloc[0]\n",
    "                    # Normalize the values: scale from 1 to proportional max_value\n",
    "                    company_data.loc[:, \"normalized_value\"] = (\n",
    "                        company_data[\"value\"] / first_non_zero_value\n",
    "                    )\n",
    "                else:\n",
    "                    print(\n",
    "                        f\"Warning: No non-zero values for {company}. Skipping normalization.\"\n",
    "                    )\n",
    "                    company_data.loc[:, \"normalized_value\"] = company_data[\n",
    "                        \"value\"\n",
    "                    ]  # No normalization applied\n",
    "\n",
    "                # Plot normalized lines\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=company_data[\"quarter\"],\n",
    "                        y=company_data[\"normalized_value\"],\n",
    "                        mode=\"lines\",\n",
    "                        name=f\"{company} (normalized)\",\n",
    "                        hoverinfo=\"x+y\",\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                # Plot regular lines\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=company_data[\"quarter\"],\n",
    "                        y=company_data[\"value\"],\n",
    "                        mode=\"lines\",\n",
    "                        name=company,\n",
    "                        hoverinfo=\"x+y\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    if plot_type == \"normalized\":\n",
    "        # Calculate the average of actual values for each quarter\n",
    "        average_data = data.groupby(\"quarter\")[\"value\"].mean().reset_index()\n",
    "\n",
    "        # Normalize the average value (just like individual company values)\n",
    "        first_non_zero_avg = average_data[\"value\"][average_data[\"value\"] != 0].iloc[0]\n",
    "        average_data[\"normalized_value\"] = average_data[\"value\"] / first_non_zero_avg\n",
    "\n",
    "        # Add the average normalized line to the plot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=average_data[\"quarter\"],\n",
    "                y=average_data[\"normalized_value\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Average (normalized)\",\n",
    "                line=dict(dash=\"dash\", color=\"black\"),\n",
    "                hoverinfo=\"x+y\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        y_axis_title = \"Normalized Value (Proportional to 1)\"\n",
    "    else:\n",
    "        # Calculate the average value for each quarter\n",
    "        average_data = data.groupby(\"quarter\")[\"value\"].mean().reset_index()\n",
    "\n",
    "        # Add the average line to the plot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=average_data[\"quarter\"],\n",
    "                y=average_data[\"value\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Average\",\n",
    "                line=dict(dash=\"dash\", color=\"black\"),\n",
    "                hoverinfo=\"x+y\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        y_axis_title = description\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f\"Comparison of {account} - {description}\",\n",
    "        xaxis_title=\"Quarter\",\n",
    "        yaxis_title=y_axis_title,\n",
    "        template=\"plotly_white\",\n",
    "        showlegend=True,\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "data = plot_company_comparison(\n",
    "    df=df,  # Your DataFrame containing the financial data\n",
    "    companies=[\"OI SA\", \"TELEFONICA BRASIL SA\", \"TIM SA\"],\n",
    "    account=\"01.01.01\",  # Example account code for \"Lucro do Período\"\n",
    "    start_date=\"2013-12-31\",  # Filter from this date\n",
    "    end_date=\"2020-12-31\",  # Optional: Filter until this date\n",
    "    plot_type=\"lines\",  # Choose between \"lines\" and \"normalized\"\n",
    ")\n",
    "# Example usage:\n",
    "data = plot_company_comparison(\n",
    "    df=df,  # Your DataFrame containing the financial data\n",
    "    companies=[\"OI SA\", \"TELEFONICA BRASIL SA\", \"TIM SA\"],\n",
    "    account=\"03.01\",  # Example account code for \"Lucro do Período\"\n",
    "    # start_date='2020-12-31',  # Filter from this date\n",
    "    # end_date='2023-12-31',     # Optional: Filter until this date\n",
    "    plot_type=\"normalized\",  # Choose between \"lines\" and \"normalized\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### World Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie = \"1\"\n",
    "\n",
    "url = f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{serie}/dados?formato=json\"\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_data(df):\n",
    "    # Remover a informação de fuso horário (timezone) antes de converter para períodos\n",
    "    df.index = df.index.tz_localize(None)\n",
    "\n",
    "    # Criar uma coluna de trimestre ('Quarter')\n",
    "    df[\"quarter\"] = df.index.to_period(\"Q\")\n",
    "\n",
    "    # Calcular a mediana de 'Adj Close' por trimestre\n",
    "    median = df.groupby(\"quarter\")[\"value\"].median()\n",
    "    # mean = df.groupby('quarter')['Adj Close'].mean()\n",
    "\n",
    "    # Convert last_dates to the actual last date of the quarter\n",
    "    # Using the 'Q' period information from 'Quarter'\n",
    "    last_quarter_dates = df[\"quarter\"].map(lambda x: x.end_time)\n",
    "\n",
    "    # Converter as datas para manter apenas a parte da data (sem tempo)\n",
    "    last_quarter_dates = last_quarter_dates.dt.date.drop_duplicates()\n",
    "\n",
    "    # Criar um DataFrame com a última data correta de cada trimestre e a mediana trimestral\n",
    "    quarterly_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"quarter\": last_quarter_dates.values,  # Drop duplicates to keep one last date per quarter\n",
    "            \"median\": median.values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return quarterly_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = [\n",
    "    \"ELETROMIDIA SA\",\n",
    "    \"ALGAR TELECOM SA\",\n",
    "    \"BRISANET PARTICIPACOES SA\",\n",
    "    \"DESKTOP SA\",\n",
    "    \"GIGA MAIS FIBRA TELECOMUNICACOES SA\",\n",
    "    \"OI SA\",\n",
    "    \"TELEC BRASILEIRAS SA TELEBRAS\",\n",
    "    \"TELEFONICA BRASIL SA\",\n",
    "    \"TIM SA\",\n",
    "    \"UNIFIQUE TELECOMUNICACOES SA\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sector = 'COMUNICACOES'\n",
    "db_file = f\"..\\data\\{settings.db_filepath}\"\n",
    "\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch all table names excluding internal SQLite tables\n",
    "cursor.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\"\n",
    ")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM company_info\", conn)\n",
    "companies = df[df[\"ticker_codes\"] != \"\"]\n",
    "companies = companies[\n",
    "    [\"cvm_code\", \"company_name\", \"ticker\", \"ticker_codes\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique ticker codes from the 'ticker_codes' column\n",
    "ticker_codes = companies[\"ticker_codes\"].unique()\n",
    "\n",
    "# Split the comma-separated ticker codes, flatten the list, and append '.SA' if necessary\n",
    "ticker_list = [\n",
    "    f\"{code.strip()}.SA\" if not code.strip().endswith(\".SA\") else code.strip()\n",
    "    for tickers in ticker_codes\n",
    "    for code in tickers.split(\",\")\n",
    "    if code\n",
    "]\n",
    "\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique ticker codes from the 'ticker_codes' column\n",
    "ticker_codes = companies[\"ticker_codes\"].unique()\n",
    "\n",
    "# Split the comma-separated ticker codes, flatten the list, and append '.SA' if necessary\n",
    "ticker_list = [\n",
    "    f\"{code.strip()}.SA\" if not code.strip().endswith(\".SA\") else code.strip()\n",
    "    for tickers in ticker_codes\n",
    "    for code in tickers.split(\",\")\n",
    "    if code\n",
    "]\n",
    "\n",
    "# Remove empty strings (if any) and display the result\n",
    "companies = [code for code in ticker_list if code]\n",
    "len(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar os dados\n",
    "last_date = \"1900-01-01\"\n",
    "# companies = ['AAPL', 'ITUB3.SA', 'ITUB4.SA', 'GOOG']\n",
    "data = yf.download(\" \".join(companies), start=last_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data = {}\n",
    "companies2 = []\n",
    "data_error = {}\n",
    "start_time = time.time()\n",
    "for i, company in enumerate(companies):\n",
    "    try:\n",
    "        # Selecionar os dados de company e remover NaNs\n",
    "        df = data.xs(company, axis=1, level=1).dropna()\n",
    "        df[\"value\"] = df[\"Adj Close\"]\n",
    "\n",
    "        # get median data from df\n",
    "        df = get_median_data(df)\n",
    "\n",
    "        historical_data[company] = df\n",
    "        companies2.append(company)\n",
    "        extra_info = [company]\n",
    "        print_info(i, extra_info, start_time, len(companies))\n",
    "    except Exception as e:\n",
    "        data_error[company] = company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find the overall min and max quarter across all tickers\n",
    "all_quarters = [data[\"quarter\"] for data in historical_data.values()]\n",
    "max_quarter = pd.concat(all_quarters).max()\n",
    "previous_quarter = pd.Period(max_quarter, freq=\"Q\") - 1\n",
    "last_date = previous_quarter.end_time.date()\n",
    "\n",
    "data2 = yf.download(\" \".join(companies2), start=last_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(files):\n",
    "    \"\"\"\n",
    "    Run financial data from the database and process it into DataFrames.\n",
    "\n",
    "    Args:\n",
    "        files (str): The name part of the database file to load.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are sectors and values are DataFrames containing the NSD data for that sector.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        db_file = os.path.join(\n",
    "            settings.data_folder, f\"{settings.db_filepath.split('.')[0]} {files}.db\"\n",
    "        )\n",
    "        db_file = \"D:/Fausto Stangler/Documentos/Python/FLY/backend/data/b3 standard.db\"\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Fetch all table names excluding internal SQLite tables\n",
    "        cursor.execute(\n",
    "            \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\"\n",
    "        )\n",
    "        tables = cursor.fetchall()\n",
    "\n",
    "        dfs = {}\n",
    "        total_lines = 0\n",
    "        start_time = time.time()  # Initialize start time for progress tracking\n",
    "\n",
    "        # Iterate through each table (sector) and process the data\n",
    "        for i, table in enumerate(tables):\n",
    "            try:\n",
    "                sector = table[0]\n",
    "                df = pd.read_sql_query(f\"SELECT * FROM {sector}\", conn)\n",
    "\n",
    "                # Normalize date columns to datetime format\n",
    "                df[\"quarter\"] = pd.to_datetime(df[\"quarter\"], errors=\"coerce\")\n",
    "\n",
    "                # Normalize numeric columns\n",
    "                df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "                # Fill missing 'value' with 0\n",
    "                df[\"value\"] = df[\"value\"].fillna(0)\n",
    "\n",
    "                # Identify rows where 'account' is missing or NaN and 'value' has been set to 0\n",
    "                missing_account = df[\"account\"].isna() | df[\"account\"].str.strip().eq(\n",
    "                    \"\"\n",
    "                )\n",
    "                df.loc[missing_account, \"account\"] = (\n",
    "                    \"0\"  # Set 'account' to '0' (as text) for these rows\n",
    "                )\n",
    "\n",
    "                # Filter out only the latest versions for each group\n",
    "                # df, _ = self.filter_newer_versions(df)\n",
    "                dfs[sector] = df  # Store the DataFrame with the sector as the key\n",
    "                total_lines += len(df)  # Update the total number of processed lines\n",
    "\n",
    "                # Display progress\n",
    "                extra_info = [\n",
    "                    f\"Loaded {len(df)} items from {sector} in {files}, total {total_lines}\"\n",
    "                ]\n",
    "                print_info(\n",
    "                    i, extra_info, start_time, len(tables)\n",
    "                )  # Removed the total_files argument\n",
    "\n",
    "                print(\"break\")\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                # system.log_error(f\"Error processing table {table}: {e}\")\n",
    "                print(e)\n",
    "\n",
    "        conn.close()\n",
    "        return dfs\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # system.log_error(f\"Error loading existing financial statements: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_company_data():\n",
    "\n",
    "    company_data = {}\n",
    "\n",
    "    try:\n",
    "        db_file = os.path.join(settings.data_folder, f\"{settings.db_filepath}\")\n",
    "        db_file = \"D:/Fausto Stangler/Documentos/Python/FLY/backend/data/b3.db\"\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        cursor.execute(f\"SELECT * FROM {settings.company_table}\")\n",
    "\n",
    "        for row in cursor.fetchall():\n",
    "            company_name = row[settings.company_columns.index(\"company_name\")]\n",
    "            company_data[company_name] = dict(zip(settings.company_columns, row))\n",
    "\n",
    "    except Exception as e:\n",
    "        # system.log_error(e)\n",
    "        print(e)\n",
    "\n",
    "    return company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_data(df):\n",
    "    # Remover a informação de fuso horário (timezone) antes de converter para períodos\n",
    "    df.index = df.index.tz_localize(None)\n",
    "\n",
    "    # Criar uma coluna de trimestre ('Quarter')\n",
    "    df[\"quarter\"] = df.index.to_period(\"Q\")\n",
    "\n",
    "    # Calcular a mediana de 'Adj Close' por trimestre\n",
    "    median = df.groupby(\"quarter\")[\"value\"].median()\n",
    "    # mean = df.groupby('quarter')['Adj Close'].mean()\n",
    "\n",
    "    # Convert last_dates to the actual last date of the quarter\n",
    "    # Using the 'Q' period information from 'Quarter'\n",
    "    last_quarter_dates = df[\"quarter\"].map(lambda x: x.end_time)\n",
    "\n",
    "    # Converter as datas para manter apenas a parte da data (sem tempo)\n",
    "    last_quarter_dates = last_quarter_dates.dt.date.drop_duplicates()\n",
    "\n",
    "    # Criar um DataFrame com a última data correta de cada trimestre e a mediana trimestral\n",
    "    quarterly_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"quarter\": last_quarter_dates.values,  # Drop duplicates to keep one last date per quarter\n",
    "            \"median\": median.values,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return quarterly_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.14% 1+13, 0.480669s per item, Time: 0h 00m 00s + 0h 00m 06s Loaded 90669 items from COMUNICACOES in standard, total 90669\n",
      "break\n"
     ]
    }
   ],
   "source": [
    "statements_data = load_data(settings.statements_standard)\n",
    "df_statements = statements_data[\"COMUNICACOES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_companies = load_company_data()\n",
    "df_companies = pd.DataFrame(all_companies).T.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge statements and company info\n",
    "\n",
    "columns = [\"company_name\"]\n",
    "cols_to_merge = columns + [\n",
    "    \"cvm_code\",\n",
    "    \"ticker\",\n",
    "    \"ticker_codes\",\n",
    "    \"isin_codes\",\n",
    "    \"listing\",\n",
    "]\n",
    "# Merge the two DataFrames on the 'company_name' column\n",
    "df_statements_companies = pd.merge(\n",
    "    df_statements, df_companies[cols_to_merge], on=columns, how=\"left\"\n",
    ")\n",
    "\n",
    "list_of_tickers = df_statements_companies[\n",
    "    [\"company_name\", \"ticker_codes\"]\n",
    "].drop_duplicates()\n",
    "list_of_quarters = df_statements_companies[\n",
    "    [\"company_name\", \"ticker_codes\", \"quarter\"]\n",
    "].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELETROMIDIA SA ELMD3\n",
      "BRISANET PARTICIPACOES SA BRIT3\n",
      "DESKTOP SA DESK3\n",
      "OI SA OIBR3\n",
      "OI SA OIBR4\n",
      "TELEC BRASILEIRAS SA TELEBRAS TELB3\n",
      "TELEC BRASILEIRAS SA TELEBRAS TELB4\n",
      "TELEFONICA BRASIL SA VIVT3\n",
      "TIM SA TIMS3\n",
      "UNIFIQUE TELECOMUNICACOES SA FIQE3\n"
     ]
    }
   ],
   "source": [
    "# get historical data from yahoo finance\n",
    "\n",
    "historical_data = {}\n",
    "last_date = \"1950-01-01\"\n",
    "\n",
    "# Iterate over each row and process tickers\n",
    "for index, row in list_of_tickers.iterrows():\n",
    "    company_name = row[\"company_name\"]\n",
    "    tickers = row[\"ticker_codes\"]\n",
    "\n",
    "    # Ensure that tickers are passed as a list by splitting any comma-separated string\n",
    "    tickers = tickers.split(\",\") if isinstance(tickers, str) else tickers\n",
    "\n",
    "    for ticker in tickers:\n",
    "\n",
    "        if ticker:\n",
    "            print(company_name, ticker)\n",
    "            df = yf.download(\n",
    "                ticker + \".SA\", start=last_date, group_by=\"ticker\", progress=False\n",
    "            )\n",
    "            df[\"value\"] = df[\"Adj Close\"]\n",
    "            df = get_median_data(df)\n",
    "\n",
    "        historical_data[ticker] = df\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELETROMIDIA SA 2019-12-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2020-03-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2020-06-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2020-09-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2020-12-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2021-03-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2021-06-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2021-09-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2021-12-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2022-03-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2022-06-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2022-09-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2022-12-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2023-03-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2023-06-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2023-09-30 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2023-12-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2024-03-31 00:00:00 ELMD 3\n",
      "ELETROMIDIA SA 2024-06-30 00:00:00 ELMD 3\n",
      "BRISANET PARTICIPACOES SA 2020-12-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2021-03-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2021-06-30 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2021-09-30 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2021-12-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2022-03-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2022-06-30 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2022-09-30 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2022-12-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2023-03-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2023-06-30 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2023-09-30 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2023-12-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2024-03-31 00:00:00 BRIT 3\n",
      "BRISANET PARTICIPACOES SA 2024-06-30 00:00:00 BRIT 3\n",
      "DESKTOP SA 2020-12-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2021-03-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2021-06-30 00:00:00 DESK 3\n",
      "DESKTOP SA 2021-09-30 00:00:00 DESK 3\n",
      "DESKTOP SA 2021-12-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2022-03-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2022-06-30 00:00:00 DESK 3\n",
      "DESKTOP SA 2022-09-30 00:00:00 DESK 3\n",
      "DESKTOP SA 2022-12-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2023-03-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2023-06-30 00:00:00 DESK 3\n",
      "DESKTOP SA 2023-09-30 00:00:00 DESK 3\n",
      "DESKTOP SA 2023-12-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2024-03-31 00:00:00 DESK 3\n",
      "DESKTOP SA 2024-06-30 00:00:00 DESK 3\n",
      "OI SA 2010-12-31 00:00:00 OIBR 3\n",
      "OI SA 2010-12-31 00:00:00 OIBR 4\n",
      "OI SA 2011-03-31 00:00:00 OIBR 3\n",
      "OI SA 2011-03-31 00:00:00 OIBR 4\n",
      "OI SA 2011-06-30 00:00:00 OIBR 3\n",
      "OI SA 2011-06-30 00:00:00 OIBR 4\n",
      "OI SA 2011-09-30 00:00:00 OIBR 3\n",
      "OI SA 2011-09-30 00:00:00 OIBR 4\n",
      "OI SA 2011-12-31 00:00:00 OIBR 3\n",
      "OI SA 2011-12-31 00:00:00 OIBR 4\n",
      "OI SA 2012-03-31 00:00:00 OIBR 3\n",
      "OI SA 2012-03-31 00:00:00 OIBR 4\n",
      "OI SA 2012-06-30 00:00:00 OIBR 3\n",
      "OI SA 2012-06-30 00:00:00 OIBR 4\n",
      "OI SA 2012-09-30 00:00:00 OIBR 3\n",
      "OI SA 2012-09-30 00:00:00 OIBR 4\n",
      "OI SA 2012-12-31 00:00:00 OIBR 3\n",
      "OI SA 2012-12-31 00:00:00 OIBR 4\n",
      "OI SA 2013-03-31 00:00:00 OIBR 3\n",
      "OI SA 2013-03-31 00:00:00 OIBR 4\n",
      "OI SA 2013-06-30 00:00:00 OIBR 3\n",
      "OI SA 2013-06-30 00:00:00 OIBR 4\n",
      "OI SA 2013-09-30 00:00:00 OIBR 3\n",
      "OI SA 2013-09-30 00:00:00 OIBR 4\n",
      "OI SA 2013-12-31 00:00:00 OIBR 3\n",
      "OI SA 2013-12-31 00:00:00 OIBR 4\n",
      "OI SA 2014-03-31 00:00:00 OIBR 3\n",
      "OI SA 2014-03-31 00:00:00 OIBR 4\n",
      "OI SA 2014-06-30 00:00:00 OIBR 3\n",
      "OI SA 2014-06-30 00:00:00 OIBR 4\n",
      "OI SA 2014-09-30 00:00:00 OIBR 3\n",
      "OI SA 2014-09-30 00:00:00 OIBR 4\n",
      "OI SA 2014-12-31 00:00:00 OIBR 3\n",
      "OI SA 2014-12-31 00:00:00 OIBR 4\n",
      "OI SA 2015-03-31 00:00:00 OIBR 3\n",
      "OI SA 2015-03-31 00:00:00 OIBR 4\n",
      "OI SA 2015-06-30 00:00:00 OIBR 3\n",
      "OI SA 2015-06-30 00:00:00 OIBR 4\n",
      "OI SA 2015-09-30 00:00:00 OIBR 3\n",
      "OI SA 2015-09-30 00:00:00 OIBR 4\n",
      "OI SA 2015-12-31 00:00:00 OIBR 3\n",
      "OI SA 2015-12-31 00:00:00 OIBR 4\n",
      "OI SA 2016-03-31 00:00:00 OIBR 3\n",
      "OI SA 2016-03-31 00:00:00 OIBR 4\n",
      "OI SA 2016-06-30 00:00:00 OIBR 3\n",
      "OI SA 2016-06-30 00:00:00 OIBR 4\n",
      "OI SA 2016-09-30 00:00:00 OIBR 3\n",
      "OI SA 2016-09-30 00:00:00 OIBR 4\n",
      "OI SA 2016-12-31 00:00:00 OIBR 3\n",
      "OI SA 2016-12-31 00:00:00 OIBR 4\n",
      "OI SA 2017-03-31 00:00:00 OIBR 3\n",
      "OI SA 2017-03-31 00:00:00 OIBR 4\n",
      "OI SA 2017-06-30 00:00:00 OIBR 3\n",
      "OI SA 2017-06-30 00:00:00 OIBR 4\n",
      "OI SA 2017-09-30 00:00:00 OIBR 3\n",
      "OI SA 2017-09-30 00:00:00 OIBR 4\n",
      "OI SA 2017-12-31 00:00:00 OIBR 3\n",
      "OI SA 2017-12-31 00:00:00 OIBR 4\n",
      "OI SA 2018-03-31 00:00:00 OIBR 3\n",
      "OI SA 2018-03-31 00:00:00 OIBR 4\n",
      "OI SA 2018-06-30 00:00:00 OIBR 3\n",
      "OI SA 2018-06-30 00:00:00 OIBR 4\n",
      "OI SA 2018-09-30 00:00:00 OIBR 3\n",
      "OI SA 2018-09-30 00:00:00 OIBR 4\n",
      "OI SA 2018-12-31 00:00:00 OIBR 3\n",
      "OI SA 2018-12-31 00:00:00 OIBR 4\n",
      "OI SA 2019-03-31 00:00:00 OIBR 3\n",
      "OI SA 2019-03-31 00:00:00 OIBR 4\n",
      "OI SA 2019-06-30 00:00:00 OIBR 3\n",
      "OI SA 2019-06-30 00:00:00 OIBR 4\n",
      "OI SA 2019-09-30 00:00:00 OIBR 3\n",
      "OI SA 2019-09-30 00:00:00 OIBR 4\n",
      "OI SA 2019-12-31 00:00:00 OIBR 3\n",
      "OI SA 2019-12-31 00:00:00 OIBR 4\n",
      "OI SA 2020-03-31 00:00:00 OIBR 3\n",
      "OI SA 2020-03-31 00:00:00 OIBR 4\n",
      "OI SA 2020-06-30 00:00:00 OIBR 3\n",
      "OI SA 2020-06-30 00:00:00 OIBR 4\n",
      "OI SA 2020-09-30 00:00:00 OIBR 3\n",
      "OI SA 2020-09-30 00:00:00 OIBR 4\n",
      "OI SA 2020-12-31 00:00:00 OIBR 3\n",
      "OI SA 2020-12-31 00:00:00 OIBR 4\n",
      "OI SA 2021-03-31 00:00:00 OIBR 3\n",
      "OI SA 2021-03-31 00:00:00 OIBR 4\n",
      "OI SA 2021-06-30 00:00:00 OIBR 3\n",
      "OI SA 2021-06-30 00:00:00 OIBR 4\n",
      "OI SA 2021-09-30 00:00:00 OIBR 3\n",
      "OI SA 2021-09-30 00:00:00 OIBR 4\n",
      "OI SA 2021-12-31 00:00:00 OIBR 3\n",
      "OI SA 2021-12-31 00:00:00 OIBR 4\n",
      "OI SA 2022-03-31 00:00:00 OIBR 3\n",
      "OI SA 2022-03-31 00:00:00 OIBR 4\n",
      "OI SA 2022-06-30 00:00:00 OIBR 3\n",
      "OI SA 2022-06-30 00:00:00 OIBR 4\n",
      "OI SA 2022-09-30 00:00:00 OIBR 3\n",
      "OI SA 2022-09-30 00:00:00 OIBR 4\n",
      "OI SA 2022-12-31 00:00:00 OIBR 3\n",
      "OI SA 2022-12-31 00:00:00 OIBR 4\n",
      "OI SA 2023-03-31 00:00:00 OIBR 3\n",
      "OI SA 2023-03-31 00:00:00 OIBR 4\n",
      "OI SA 2023-06-30 00:00:00 OIBR 3\n",
      "OI SA 2023-06-30 00:00:00 OIBR 4\n",
      "OI SA 2023-09-30 00:00:00 OIBR 3\n",
      "OI SA 2023-09-30 00:00:00 OIBR 4\n",
      "OI SA 2023-12-31 00:00:00 OIBR 3\n",
      "OI SA 2023-12-31 00:00:00 OIBR 4\n",
      "OI SA 2024-03-31 00:00:00 OIBR 3\n",
      "OI SA 2024-03-31 00:00:00 OIBR 4\n",
      "OI SA 2024-06-30 00:00:00 OIBR 3\n",
      "OI SA 2024-06-30 00:00:00 OIBR 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2010-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2010-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2011-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2012-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2013-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2014-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2015-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2016-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2017-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2018-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2019-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2020-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2021-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2022-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-06-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-09-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-09-30 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-12-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2023-12-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2024-03-31 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2024-03-31 00:00:00 TELB 4\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2024-06-30 00:00:00 TELB 3\n",
      "TELEC BRASILEIRAS SA TELEBRAS 2024-06-30 00:00:00 TELB 4\n",
      "TELEFONICA BRASIL SA 2010-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2011-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2011-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2011-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2011-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2012-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2012-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2012-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2012-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2013-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2013-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2013-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2013-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2014-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2014-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2014-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2014-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2015-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2015-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2015-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2015-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2016-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2016-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2016-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2016-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2017-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2017-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2017-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2017-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2018-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2018-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2018-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2018-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2019-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2019-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2019-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2019-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2020-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2020-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2020-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2020-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2021-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2021-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2021-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2021-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2022-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2022-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2022-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2022-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2023-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2023-06-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2023-09-30 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2023-12-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2024-03-31 00:00:00 VIVT 3\n",
      "TELEFONICA BRASIL SA 2024-06-30 00:00:00 VIVT 3\n",
      "TIM SA 2018-12-31 00:00:00 TIMS 3\n",
      "TIM SA 2019-03-31 00:00:00 TIMS 3\n",
      "TIM SA 2019-06-30 00:00:00 TIMS 3\n",
      "TIM SA 2019-09-30 00:00:00 TIMS 3\n",
      "TIM SA 2019-12-31 00:00:00 TIMS 3\n",
      "TIM SA 2020-03-31 00:00:00 TIMS 3\n",
      "TIM SA 2020-06-30 00:00:00 TIMS 3\n",
      "TIM SA 2020-09-30 00:00:00 TIMS 3\n",
      "TIM SA 2020-12-31 00:00:00 TIMS 3\n",
      "TIM SA 2021-03-31 00:00:00 TIMS 3\n",
      "TIM SA 2021-06-30 00:00:00 TIMS 3\n",
      "TIM SA 2021-09-30 00:00:00 TIMS 3\n",
      "TIM SA 2021-12-31 00:00:00 TIMS 3\n",
      "TIM SA 2022-03-31 00:00:00 TIMS 3\n",
      "TIM SA 2022-06-30 00:00:00 TIMS 3\n",
      "TIM SA 2022-09-30 00:00:00 TIMS 3\n",
      "TIM SA 2022-12-31 00:00:00 TIMS 3\n",
      "TIM SA 2023-03-31 00:00:00 TIMS 3\n",
      "TIM SA 2023-06-30 00:00:00 TIMS 3\n",
      "TIM SA 2023-09-30 00:00:00 TIMS 3\n",
      "TIM SA 2023-12-31 00:00:00 TIMS 3\n",
      "TIM SA 2024-03-31 00:00:00 TIMS 3\n",
      "TIM SA 2024-06-30 00:00:00 TIMS 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2020-12-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2021-03-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2021-06-30 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2021-09-30 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2021-12-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2022-03-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2022-06-30 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2022-09-30 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2022-12-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2023-03-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2023-06-30 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2023-09-30 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2023-12-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2024-03-31 00:00:00 FIQE 3\n",
      "UNIFIQUE TELECOMUNICACOES SA 2024-06-30 00:00:00 FIQE 3\n"
     ]
    }
   ],
   "source": [
    "# create new historical data rows\n",
    "\n",
    "new_rows = []\n",
    "for i, row in list_of_quarters.iterrows():\n",
    "    company_name = row[\"company_name\"]\n",
    "    quarter = row[\"quarter\"]\n",
    "    tickers = row[\"ticker_codes\"]\n",
    "\n",
    "    tickers = tickers.split(\",\") if isinstance(tickers, str) else tickers\n",
    "    for ticker in tickers:\n",
    "        if ticker:\n",
    "            # Separate ticker into no digits and only digits\n",
    "            tick = \"\".join(\n",
    "                [char for char in ticker if not char.isdigit()]\n",
    "            )  # Ticker without digits\n",
    "            ticker_digit = \"\".join(\n",
    "                [char for char in ticker if char.isdigit()]\n",
    "            )  # Only digits\n",
    "\n",
    "            mask = df_statements_companies[\"company_name\"] == company_name\n",
    "            mask &= df_statements_companies[\"quarter\"] == quarter\n",
    "            mask &= df_statements_companies[\"ticker\"] == tick\n",
    "\n",
    "            new_row = df_statements_companies[mask].iloc[0].copy()\n",
    "\n",
    "            # Modify the necessary columns in the copied row\n",
    "            new_row[\"type\"] = \"Cotações Históricas\"\n",
    "            new_row[\"frame\"] = settings.tipos_acoes[ticker_digit]\n",
    "            new_row[\"account\"] = (\n",
    "                f\"99.{ticker_digit}\"  # ticker_digit is assumed to be extracted from the original ticker\n",
    "            )\n",
    "            new_row[\"description\"] = \"Cotação Mediana do Trimestre\"\n",
    "\n",
    "            # Ensure 'quarter' in 'historical_data' is converted to datetime\n",
    "            df_historical_data = historical_data.get(\n",
    "                tick + ticker_digit, pd.DataFrame()\n",
    "            )  # Use .get() to avoid KeyError if key doesn't exist\n",
    "            if df_historical_data.empty:\n",
    "                new_value = pd.NA\n",
    "            else:\n",
    "                df_historical_data[\"quarter\"] = pd.to_datetime(\n",
    "                    df_historical_data[\"quarter\"]\n",
    "                )\n",
    "\n",
    "                # Filter the 'historical_data' for the correct 'quarter' and get the 'median' value\n",
    "                mask = df_historical_data[\"quarter\"] == pd.to_datetime(quarter)\n",
    "                new_value = df_historical_data[mask][\"median\"].values\n",
    "\n",
    "                # If no values are found, set to pd.NA\n",
    "                if len(new_value) == 0:\n",
    "                    new_value = pd.NA\n",
    "                else:\n",
    "                    new_value = new_value[0]  # Extract the actual median value\n",
    "\n",
    "            # Set the new value in the new row\n",
    "            new_row[\"value\"] = new_value\n",
    "\n",
    "            new_rows.append(new_row)\n",
    "            print(company_name, quarter, tick, ticker_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nsd</th>\n",
       "      <th>sector</th>\n",
       "      <th>subsector</th>\n",
       "      <th>segment</th>\n",
       "      <th>company_name</th>\n",
       "      <th>quarter</th>\n",
       "      <th>version</th>\n",
       "      <th>type</th>\n",
       "      <th>frame</th>\n",
       "      <th>account</th>\n",
       "      <th>description</th>\n",
       "      <th>value</th>\n",
       "      <th>cvm_code</th>\n",
       "      <th>ticker</th>\n",
       "      <th>ticker_codes</th>\n",
       "      <th>isin_codes</th>\n",
       "      <th>listing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99116</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>PUBLICIDADE E PROPAGANDA</td>\n",
       "      <td>ELETROMIDIA SA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>DFs Consolidadas</td>\n",
       "      <td>Balanço Patrimonial Ativo</td>\n",
       "      <td>01</td>\n",
       "      <td>Ativo Total</td>\n",
       "      <td>2905300000.0</td>\n",
       "      <td>25569</td>\n",
       "      <td>ELMD</td>\n",
       "      <td>ELMD3</td>\n",
       "      <td>BRELMDACNOR3</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99116</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>PUBLICIDADE E PROPAGANDA</td>\n",
       "      <td>ELETROMIDIA SA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>DFs Consolidadas</td>\n",
       "      <td>Balanço Patrimonial Ativo</td>\n",
       "      <td>01.01</td>\n",
       "      <td>Ativo Circulante de Curto Prazo</td>\n",
       "      <td>1061320000.0</td>\n",
       "      <td>25569</td>\n",
       "      <td>ELMD</td>\n",
       "      <td>ELMD3</td>\n",
       "      <td>BRELMDACNOR3</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>99116</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>PUBLICIDADE E PROPAGANDA</td>\n",
       "      <td>ELETROMIDIA SA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>DFs Consolidadas</td>\n",
       "      <td>Balanço Patrimonial Ativo</td>\n",
       "      <td>01.01.01</td>\n",
       "      <td>Caixa e Equivalentes de Caixa de Curto Prazo</td>\n",
       "      <td>380180000.0</td>\n",
       "      <td>25569</td>\n",
       "      <td>ELMD</td>\n",
       "      <td>ELMD3</td>\n",
       "      <td>BRELMDACNOR3</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99116</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>PUBLICIDADE E PROPAGANDA</td>\n",
       "      <td>ELETROMIDIA SA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>DFs Consolidadas</td>\n",
       "      <td>Balanço Patrimonial Ativo</td>\n",
       "      <td>01.01.01.01</td>\n",
       "      <td>Caixa e Bancos de Curto Prazo</td>\n",
       "      <td>130980000.0</td>\n",
       "      <td>25569</td>\n",
       "      <td>ELMD</td>\n",
       "      <td>ELMD3</td>\n",
       "      <td>BRELMDACNOR3</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99116</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>MIDIA</td>\n",
       "      <td>PUBLICIDADE E PROPAGANDA</td>\n",
       "      <td>ELETROMIDIA SA</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>DFs Consolidadas</td>\n",
       "      <td>Balanço Patrimonial Ativo</td>\n",
       "      <td>01.01.01.02</td>\n",
       "      <td>Aplicações Líquidas de Curto Prazo</td>\n",
       "      <td>249200000.0</td>\n",
       "      <td>25569</td>\n",
       "      <td>ELMD</td>\n",
       "      <td>ELMD3</td>\n",
       "      <td>BRELMDACNOR3</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91026</th>\n",
       "      <td>129891</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>UNIFIQUE TELECOMUNICACOES SA</td>\n",
       "      <td>2023-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotações Históricas</td>\n",
       "      <td>Ações Ordinárias (ON)</td>\n",
       "      <td>99.3</td>\n",
       "      <td>Cotação Mediana do Trimestre</td>\n",
       "      <td>3.278778</td>\n",
       "      <td>26050</td>\n",
       "      <td>FIQE</td>\n",
       "      <td>FIQE3</td>\n",
       "      <td>BRFIQEACNOR5</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91027</th>\n",
       "      <td>131935</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>UNIFIQUE TELECOMUNICACOES SA</td>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotações Históricas</td>\n",
       "      <td>Ações Ordinárias (ON)</td>\n",
       "      <td>99.3</td>\n",
       "      <td>Cotação Mediana do Trimestre</td>\n",
       "      <td>3.719842</td>\n",
       "      <td>26050</td>\n",
       "      <td>FIQE</td>\n",
       "      <td>FIQE3</td>\n",
       "      <td>BRFIQEACNOR5</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91028</th>\n",
       "      <td>134906</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>UNIFIQUE TELECOMUNICACOES SA</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotações Históricas</td>\n",
       "      <td>Ações Ordinárias (ON)</td>\n",
       "      <td>99.3</td>\n",
       "      <td>Cotação Mediana do Trimestre</td>\n",
       "      <td>3.490817</td>\n",
       "      <td>26050</td>\n",
       "      <td>FIQE</td>\n",
       "      <td>FIQE3</td>\n",
       "      <td>BRFIQEACNOR5</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91029</th>\n",
       "      <td>137478</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>UNIFIQUE TELECOMUNICACOES SA</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotações Históricas</td>\n",
       "      <td>Ações Ordinárias (ON)</td>\n",
       "      <td>99.3</td>\n",
       "      <td>Cotação Mediana do Trimestre</td>\n",
       "      <td>3.726683</td>\n",
       "      <td>26050</td>\n",
       "      <td>FIQE</td>\n",
       "      <td>FIQE3</td>\n",
       "      <td>BRFIQEACNOR5</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91030</th>\n",
       "      <td>140491</td>\n",
       "      <td>COMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>TELECOMUNICACOES</td>\n",
       "      <td>UNIFIQUE TELECOMUNICACOES SA</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Cotações Históricas</td>\n",
       "      <td>Ações Ordinárias (ON)</td>\n",
       "      <td>99.3</td>\n",
       "      <td>Cotação Mediana do Trimestre</td>\n",
       "      <td>3.544215</td>\n",
       "      <td>26050</td>\n",
       "      <td>FIQE</td>\n",
       "      <td>FIQE3</td>\n",
       "      <td>BRFIQEACNOR5</td>\n",
       "      <td>CIA NOVO MERCADO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91031 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          nsd        sector         subsector                   segment  \\\n",
       "0       99116  COMUNICACOES             MIDIA  PUBLICIDADE E PROPAGANDA   \n",
       "1       99116  COMUNICACOES             MIDIA  PUBLICIDADE E PROPAGANDA   \n",
       "2       99116  COMUNICACOES             MIDIA  PUBLICIDADE E PROPAGANDA   \n",
       "3       99116  COMUNICACOES             MIDIA  PUBLICIDADE E PROPAGANDA   \n",
       "4       99116  COMUNICACOES             MIDIA  PUBLICIDADE E PROPAGANDA   \n",
       "...       ...           ...               ...                       ...   \n",
       "91026  129891  COMUNICACOES  TELECOMUNICACOES          TELECOMUNICACOES   \n",
       "91027  131935  COMUNICACOES  TELECOMUNICACOES          TELECOMUNICACOES   \n",
       "91028  134906  COMUNICACOES  TELECOMUNICACOES          TELECOMUNICACOES   \n",
       "91029  137478  COMUNICACOES  TELECOMUNICACOES          TELECOMUNICACOES   \n",
       "91030  140491  COMUNICACOES  TELECOMUNICACOES          TELECOMUNICACOES   \n",
       "\n",
       "                       company_name    quarter version                 type  \\\n",
       "0                    ELETROMIDIA SA 2019-12-31       1     DFs Consolidadas   \n",
       "1                    ELETROMIDIA SA 2019-12-31       1     DFs Consolidadas   \n",
       "2                    ELETROMIDIA SA 2019-12-31       1     DFs Consolidadas   \n",
       "3                    ELETROMIDIA SA 2019-12-31       1     DFs Consolidadas   \n",
       "4                    ELETROMIDIA SA 2019-12-31       1     DFs Consolidadas   \n",
       "...                             ...        ...     ...                  ...   \n",
       "91026  UNIFIQUE TELECOMUNICACOES SA 2023-06-30       1  Cotações Históricas   \n",
       "91027  UNIFIQUE TELECOMUNICACOES SA 2023-09-30       1  Cotações Históricas   \n",
       "91028  UNIFIQUE TELECOMUNICACOES SA 2023-12-31       1  Cotações Históricas   \n",
       "91029  UNIFIQUE TELECOMUNICACOES SA 2024-03-31       1  Cotações Históricas   \n",
       "91030  UNIFIQUE TELECOMUNICACOES SA 2024-06-30       1  Cotações Históricas   \n",
       "\n",
       "                           frame      account  \\\n",
       "0      Balanço Patrimonial Ativo           01   \n",
       "1      Balanço Patrimonial Ativo        01.01   \n",
       "2      Balanço Patrimonial Ativo     01.01.01   \n",
       "3      Balanço Patrimonial Ativo  01.01.01.01   \n",
       "4      Balanço Patrimonial Ativo  01.01.01.02   \n",
       "...                          ...          ...   \n",
       "91026      Ações Ordinárias (ON)         99.3   \n",
       "91027      Ações Ordinárias (ON)         99.3   \n",
       "91028      Ações Ordinárias (ON)         99.3   \n",
       "91029      Ações Ordinárias (ON)         99.3   \n",
       "91030      Ações Ordinárias (ON)         99.3   \n",
       "\n",
       "                                        description         value cvm_code  \\\n",
       "0                                       Ativo Total  2905300000.0    25569   \n",
       "1                   Ativo Circulante de Curto Prazo  1061320000.0    25569   \n",
       "2      Caixa e Equivalentes de Caixa de Curto Prazo   380180000.0    25569   \n",
       "3                     Caixa e Bancos de Curto Prazo   130980000.0    25569   \n",
       "4                Aplicações Líquidas de Curto Prazo   249200000.0    25569   \n",
       "...                                             ...           ...      ...   \n",
       "91026                  Cotação Mediana do Trimestre      3.278778    26050   \n",
       "91027                  Cotação Mediana do Trimestre      3.719842    26050   \n",
       "91028                  Cotação Mediana do Trimestre      3.490817    26050   \n",
       "91029                  Cotação Mediana do Trimestre      3.726683    26050   \n",
       "91030                  Cotação Mediana do Trimestre      3.544215    26050   \n",
       "\n",
       "      ticker ticker_codes    isin_codes           listing  \n",
       "0       ELMD        ELMD3  BRELMDACNOR3  CIA NOVO MERCADO  \n",
       "1       ELMD        ELMD3  BRELMDACNOR3  CIA NOVO MERCADO  \n",
       "2       ELMD        ELMD3  BRELMDACNOR3  CIA NOVO MERCADO  \n",
       "3       ELMD        ELMD3  BRELMDACNOR3  CIA NOVO MERCADO  \n",
       "4       ELMD        ELMD3  BRELMDACNOR3  CIA NOVO MERCADO  \n",
       "...      ...          ...           ...               ...  \n",
       "91026   FIQE        FIQE3  BRFIQEACNOR5  CIA NOVO MERCADO  \n",
       "91027   FIQE        FIQE3  BRFIQEACNOR5  CIA NOVO MERCADO  \n",
       "91028   FIQE        FIQE3  BRFIQEACNOR5  CIA NOVO MERCADO  \n",
       "91029   FIQE        FIQE3  BRFIQEACNOR5  CIA NOVO MERCADO  \n",
       "91030   FIQE        FIQE3  BRFIQEACNOR5  CIA NOVO MERCADO  \n",
       "\n",
       "[91031 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# insert new rows into df_statements_companies\n",
    "\n",
    "df_final = pd.concat(\n",
    "    [df_statements_companies, pd.DataFrame(new_rows)], ignore_index=True\n",
    ").drop_duplicates()\n",
    "\n",
    "mask = df_final[\"ticker\"] == \"ELMD\"\n",
    "# mask&= df_historical_statements_2['quarter'] == '2020-12-31'\n",
    "mask &= df_final[\"type\"] == \"Cotações Históricas\"\n",
    "\n",
    "df_final\n",
    "\n",
    "# sort and select only statement columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finantial Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = \"COMUNICACOES\"\n",
    "db_file = f\"..\\data\\{settings.db_filepath.split('.')[0]} {settings.markets_file}.db\"\n",
    "\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Fetch all table names excluding internal SQLite tables\n",
    "cursor.execute(\n",
    "    \"SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%';\"\n",
    ")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "df = pd.read_sql_query(f\"SELECT * FROM {sector}\", conn)\n",
    "# df['account_description'] = df['account'] + ' - ' + df['description']\n",
    "df[\"quarter\"] = pd.to_datetime(df[\"quarter\"])\n",
    "# Store unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sector': ['COMUNICACOES'],\n",
       " 'subsector': ['MIDIA', 'TELECOMUNICACOES'],\n",
       " 'segment': ['PUBLICIDADE E PROPAGANDA', 'TELECOMUNICACOES'],\n",
       " 'company_name': ['ALGAR TELECOM SA',\n",
       "  'BRISANET PARTICIPACOES SA',\n",
       "  'DESKTOP SA',\n",
       "  'ELETROMIDIA SA',\n",
       "  'GIGA MAIS FIBRA TELECOMUNICACOES SA',\n",
       "  'OI SA',\n",
       "  'TELEC BRASILEIRAS SA TELEBRAS',\n",
       "  'TELEFONICA BRASIL SA',\n",
       "  'TIM SA',\n",
       "  'UNIFIQUE TELECOMUNICACOES SA'],\n",
       " 'quarter': [Timestamp('2010-12-31 00:00:00'),\n",
       "  Timestamp('2011-03-31 00:00:00'),\n",
       "  Timestamp('2011-06-30 00:00:00'),\n",
       "  Timestamp('2011-09-30 00:00:00'),\n",
       "  Timestamp('2011-12-31 00:00:00'),\n",
       "  Timestamp('2012-03-31 00:00:00'),\n",
       "  Timestamp('2012-06-30 00:00:00'),\n",
       "  Timestamp('2012-09-30 00:00:00'),\n",
       "  Timestamp('2012-12-31 00:00:00'),\n",
       "  Timestamp('2013-03-31 00:00:00'),\n",
       "  Timestamp('2013-06-30 00:00:00'),\n",
       "  Timestamp('2013-09-30 00:00:00'),\n",
       "  Timestamp('2013-12-31 00:00:00'),\n",
       "  Timestamp('2014-03-31 00:00:00'),\n",
       "  Timestamp('2014-06-30 00:00:00'),\n",
       "  Timestamp('2014-09-30 00:00:00'),\n",
       "  Timestamp('2014-12-31 00:00:00'),\n",
       "  Timestamp('2015-03-31 00:00:00'),\n",
       "  Timestamp('2015-06-30 00:00:00'),\n",
       "  Timestamp('2015-09-30 00:00:00'),\n",
       "  Timestamp('2015-12-31 00:00:00'),\n",
       "  Timestamp('2016-03-31 00:00:00'),\n",
       "  Timestamp('2016-06-30 00:00:00'),\n",
       "  Timestamp('2016-09-30 00:00:00'),\n",
       "  Timestamp('2016-12-31 00:00:00'),\n",
       "  Timestamp('2017-03-31 00:00:00'),\n",
       "  Timestamp('2017-06-30 00:00:00'),\n",
       "  Timestamp('2017-09-30 00:00:00'),\n",
       "  Timestamp('2017-12-31 00:00:00'),\n",
       "  Timestamp('2018-03-31 00:00:00'),\n",
       "  Timestamp('2018-06-30 00:00:00'),\n",
       "  Timestamp('2018-09-30 00:00:00'),\n",
       "  Timestamp('2018-12-31 00:00:00'),\n",
       "  Timestamp('2019-03-31 00:00:00'),\n",
       "  Timestamp('2019-06-30 00:00:00'),\n",
       "  Timestamp('2019-09-30 00:00:00'),\n",
       "  Timestamp('2019-12-31 00:00:00'),\n",
       "  Timestamp('2020-03-31 00:00:00'),\n",
       "  Timestamp('2020-06-30 00:00:00'),\n",
       "  Timestamp('2020-09-30 00:00:00'),\n",
       "  Timestamp('2020-12-31 00:00:00'),\n",
       "  Timestamp('2021-03-31 00:00:00'),\n",
       "  Timestamp('2021-06-30 00:00:00'),\n",
       "  Timestamp('2021-09-30 00:00:00'),\n",
       "  Timestamp('2021-12-31 00:00:00'),\n",
       "  Timestamp('2022-03-31 00:00:00'),\n",
       "  Timestamp('2022-06-30 00:00:00'),\n",
       "  Timestamp('2022-09-30 00:00:00'),\n",
       "  Timestamp('2022-12-31 00:00:00'),\n",
       "  Timestamp('2023-03-31 00:00:00'),\n",
       "  Timestamp('2023-06-30 00:00:00'),\n",
       "  Timestamp('2023-09-30 00:00:00'),\n",
       "  Timestamp('2023-12-31 00:00:00'),\n",
       "  Timestamp('2024-03-31 00:00:00'),\n",
       "  Timestamp('2024-06-30 00:00:00')],\n",
       " 'version': ['1', '2', '3', '4'],\n",
       " 'type': ['Cotações Históricas',\n",
       "  'DFs Consolidadas',\n",
       "  'DFs Individuais',\n",
       "  'Dados da Empresa'],\n",
       " 'frame': ['Balanço Patrimonial Ativo',\n",
       "  'Balanço Patrimonial Passivo',\n",
       "  'Composição do Capital',\n",
       "  'Cotação Mediana do Trimestre',\n",
       "  'Demonstração de Valor Adicionado',\n",
       "  'Demonstração do Fluxo de Caixa',\n",
       "  'Demonstração do Resultado'],\n",
       " 'account': ['00.01.01',\n",
       "  '00.01.02',\n",
       "  '00.02.01',\n",
       "  '00.02.02',\n",
       "  '01',\n",
       "  '01.01',\n",
       "  '01.01.01',\n",
       "  '01.01.01.01',\n",
       "  '01.01.01.02',\n",
       "  '01.01.02',\n",
       "  '01.01.02.01',\n",
       "  '01.01.02.02',\n",
       "  '01.01.03',\n",
       "  '01.01.03.01',\n",
       "  '01.01.03.01.01',\n",
       "  '01.01.03.01.02',\n",
       "  '01.01.03.01.03',\n",
       "  '01.01.03.02',\n",
       "  '01.01.04',\n",
       "  '01.01.04.01',\n",
       "  '01.01.04.02',\n",
       "  '01.01.04.03',\n",
       "  '01.01.05',\n",
       "  '01.01.06',\n",
       "  '01.01.07',\n",
       "  '01.01.09',\n",
       "  '01.02',\n",
       "  '01.02.01',\n",
       "  '01.02.01.02',\n",
       "  '01.02.01.03',\n",
       "  '01.02.01.04',\n",
       "  '01.02.01.05',\n",
       "  '01.02.01.06',\n",
       "  '01.02.01.07',\n",
       "  '01.02.01.08',\n",
       "  '01.02.01.09',\n",
       "  '01.02.02',\n",
       "  '01.02.02.01',\n",
       "  '01.02.02.01.01',\n",
       "  '01.02.02.01.02',\n",
       "  '01.02.02.01.03',\n",
       "  '01.02.02.02',\n",
       "  '01.02.03',\n",
       "  '01.02.03.01',\n",
       "  '01.02.03.02',\n",
       "  '01.02.04',\n",
       "  '01.02.04.01',\n",
       "  '01.02.04.01.01',\n",
       "  '01.02.04.01.02',\n",
       "  '01.02.04.01.03',\n",
       "  '01.02.04.02',\n",
       "  '01.02.04.02.01',\n",
       "  '02',\n",
       "  '02.01',\n",
       "  '02.01.01.01',\n",
       "  '02.01.01.02',\n",
       "  '02.01.02',\n",
       "  '02.01.02.01',\n",
       "  '02.01.02.02',\n",
       "  '02.01.03',\n",
       "  '02.01.03.01',\n",
       "  '02.01.03.01.01',\n",
       "  '02.01.03.01.02',\n",
       "  '02.01.03.01.03',\n",
       "  '02.01.03.02',\n",
       "  '02.01.03.03',\n",
       "  '02.01.04',\n",
       "  '02.01.04.01',\n",
       "  '02.01.04.01.01',\n",
       "  '02.01.04.01.02',\n",
       "  '02.01.04.02',\n",
       "  '02.01.04.03',\n",
       "  '02.01.05',\n",
       "  '02.01.05.01',\n",
       "  '02.01.05.01.01',\n",
       "  '02.01.05.01.03',\n",
       "  '02.01.05.01.04',\n",
       "  '02.01.05.02',\n",
       "  '02.01.05.02.01',\n",
       "  '02.01.05.02.02',\n",
       "  '02.01.05.02.03',\n",
       "  '02.01.05.02.04',\n",
       "  '02.01.05.02.09',\n",
       "  '02.01.06',\n",
       "  '02.01.06.01',\n",
       "  '02.01.06.01.01',\n",
       "  '02.01.06.01.02',\n",
       "  '02.01.06.01.03',\n",
       "  '02.01.06.01.04',\n",
       "  '02.01.06.02',\n",
       "  '02.01.06.02.01',\n",
       "  '02.01.06.02.02',\n",
       "  '02.01.06.02.03',\n",
       "  '02.02',\n",
       "  '02.02.01',\n",
       "  '02.02.01.01',\n",
       "  '02.02.01.01.01',\n",
       "  '02.02.01.01.02',\n",
       "  '02.02.01.02',\n",
       "  '02.02.01.03',\n",
       "  '02.02.02',\n",
       "  '02.02.02.01.04',\n",
       "  '02.02.03',\n",
       "  '02.02.04',\n",
       "  '02.02.04.01',\n",
       "  '02.03',\n",
       "  '02.03.01',\n",
       "  '02.03.01.01',\n",
       "  '02.03.01.02',\n",
       "  '02.03.02',\n",
       "  '02.03.02.01',\n",
       "  '02.03.02.02',\n",
       "  '02.03.02.09',\n",
       "  '02.03.03',\n",
       "  '02.03.04',\n",
       "  '02.03.04.01',\n",
       "  '02.03.04.02',\n",
       "  '02.03.04.03',\n",
       "  '02.03.04.09',\n",
       "  '02.03.05',\n",
       "  '02.03.06',\n",
       "  '02.03.06.01',\n",
       "  '02.03.06.02',\n",
       "  '02.03.06.09',\n",
       "  '02.03.07',\n",
       "  '02.03.08',\n",
       "  '02.03.09',\n",
       "  '03.01',\n",
       "  '03.02',\n",
       "  '03.03',\n",
       "  '03.04',\n",
       "  '03.04.01',\n",
       "  '03.04.01.01',\n",
       "  '03.05',\n",
       "  '03.06',\n",
       "  '03.07',\n",
       "  '03.08',\n",
       "  '03.11',\n",
       "  '03.11.01',\n",
       "  '03.11.02',\n",
       "  '06.01',\n",
       "  '06.02',\n",
       "  '06.03',\n",
       "  '07.01',\n",
       "  '07.01.01',\n",
       "  '07.01.02',\n",
       "  '07.01.03',\n",
       "  '07.01.04',\n",
       "  '07.02',\n",
       "  '07.02.01',\n",
       "  '07.02.02',\n",
       "  '07.02.03',\n",
       "  '07.02.04',\n",
       "  '07.03',\n",
       "  '07.04',\n",
       "  '07.04.01',\n",
       "  '07.04.02',\n",
       "  '07.05',\n",
       "  '07.06',\n",
       "  '07.06.01',\n",
       "  '07.06.02',\n",
       "  '07.06.03',\n",
       "  '07.06.03.01',\n",
       "  '07.06.03.02',\n",
       "  '07.07',\n",
       "  '07.08',\n",
       "  '07.08.01',\n",
       "  '07.08.01.01',\n",
       "  '07.08.01.02',\n",
       "  '07.08.01.03',\n",
       "  '07.08.01.04',\n",
       "  '07.08.02',\n",
       "  '07.08.02.01',\n",
       "  '07.08.02.02',\n",
       "  '07.08.02.03',\n",
       "  '07.08.03',\n",
       "  '07.08.03.01',\n",
       "  '07.08.03.02',\n",
       "  '07.08.03.03',\n",
       "  '07.08.04',\n",
       "  '07.08.04.01',\n",
       "  '07.08.04.02',\n",
       "  '07.08.04.03',\n",
       "  '07.08.04.04',\n",
       "  '07.08.05.01',\n",
       "  '07.08.05.02',\n",
       "  '07.08.05.03',\n",
       "  '07.08.05.04',\n",
       "  '07.08.05.09',\n",
       "  '99.3',\n",
       "  '99.4'],\n",
       " 'description': ['Ajustes Acumulados de Conversão',\n",
       "  'Ajustes Patrimoniais',\n",
       "  'Ajustes de Avaliação Patrimonial',\n",
       "  'Aluguéis',\n",
       "  'Aplicações Financeiras de Curto Prazo',\n",
       "  'Aplicações Líquidas de Curto Prazo',\n",
       "  'Aplicações a Valor Justo de Curto Prazo',\n",
       "  'Aplicações a Valor Justo de Longo Prazo',\n",
       "  'Aplicações ao Custo Amortizado de Curto Prazo',\n",
       "  'Ativo Circulante de Curto Prazo',\n",
       "  'Ativo Não Circulante de Longo Prazo',\n",
       "  'Ativo Realizável a Longo Prazo',\n",
       "  'Ativo Total',\n",
       "  'Ativos Biológicos de Curto Prazo',\n",
       "  'Ativos Biológicos de Longo Prazo',\n",
       "  'Atribuído a Sócios Não Controladores',\n",
       "  'Atribuído a Sócios da Empresa Controladora',\n",
       "  'Ações ON Ordinárias',\n",
       "  'Ações Ordinárias (ON)',\n",
       "  'Ações PN Preferenciais',\n",
       "  'Ações Preferenciais (PN)',\n",
       "  'Ações, Remuneração e Opções',\n",
       "  'Benefícios',\n",
       "  'Caixa de Financiamento',\n",
       "  'Caixa de Investimento',\n",
       "  'Caixa de Operações (Operacional)',\n",
       "  'Caixa e Bancos de Curto Prazo',\n",
       "  'Caixa e Equivalentes de Caixa de Curto Prazo',\n",
       "  'Capital Social',\n",
       "  'Capital Social Realizado',\n",
       "  'Carteira de Clientes',\n",
       "  'Clientes',\n",
       "  'Contas a Receber de Curto Prazo',\n",
       "  'Contas a Receber de Longo Prazo',\n",
       "  'Contas de Clientes de Curto Prazo',\n",
       "  'Créditos com Partes Relacionadas de Longo Prazo',\n",
       "  'Créditos de Liquidação Duvidosa',\n",
       "  'Custo dos Bens e/ou Serviços Vendidos',\n",
       "  'Custos Prods., Mercs. e Servs. Vendidos',\n",
       "  'Debêntures',\n",
       "  'Depreciação, Amortização e Exaustão',\n",
       "  'Derivativos e Participações',\n",
       "  'Despesas Antecipadas de Curto Prazo',\n",
       "  'Despesas Antecipadas de Longo Prazo',\n",
       "  'Despesas Comerciais',\n",
       "  'Despesas Operacionais',\n",
       "  'Despesas/Receitas Operacionais',\n",
       "  'Direito de Uso em Arrendamento',\n",
       "  'Distribuição do Valor Adicionado',\n",
       "  'Dividendos',\n",
       "  'Dividendos e Ações',\n",
       "  'Dividendos e Ações em Tesouraria',\n",
       "  'Débitos com Coligadas',\n",
       "  'Débitos com Controladores',\n",
       "  'Débitos com Outras Partes Relacionadas',\n",
       "  'Em Moeda Estrangeira',\n",
       "  'Em Moeda Nacional',\n",
       "  'Em Tesouraria Ações ON Ordinárias',\n",
       "  'Em Tesouraria Ações PN Preferenciais',\n",
       "  'Empréstimos e Financiamentos',\n",
       "  'Empréstimos e Financiamentos de Curto Prazo',\n",
       "  'Empréstimos e Financiamentos de Longo Prazo',\n",
       "  'Estaduais',\n",
       "  'Estoques de Curto Prazo',\n",
       "  'Estoques de Longo Prazo',\n",
       "  'Estoques de Material de Consumo de Curto Prazo',\n",
       "  'Estoques de Material para Revenda de Curto Prazo',\n",
       "  'Estoques de Outros Itens de Curto Prazo',\n",
       "  'F.G.T.S.',\n",
       "  'Federais',\n",
       "  'Financiamento por Arrendamento Financeiro',\n",
       "  'Fornecedores Estrangeiros',\n",
       "  'Fornecedores Nacionais',\n",
       "  'Fornecedores de Curto Prazo',\n",
       "  'Gastos na emissão de ações',\n",
       "  'Goodwill',\n",
       "  'Imobilizado',\n",
       "  'Imobilizado em Operação',\n",
       "  'Imposto de Renda e Contribuição Social Diferidos',\n",
       "  'Imposto de Renda e Contribuição Social a Pagar',\n",
       "  'Imposto de Renda e Contribuição Social sobre o Lucro',\n",
       "  'Impostos, Taxas e Contribuições',\n",
       "  'Insumos Adquiridos de Terceiros',\n",
       "  'Intangíveis',\n",
       "  'Intangível',\n",
       "  'Investimento Social',\n",
       "  'Investimentos',\n",
       "  'Juros',\n",
       "  'Juros sobre o Capital Próprio',\n",
       "  'Lucro do Período',\n",
       "  'Lucros Retidos',\n",
       "  'Lucros Retidos / Prejuízo do Período',\n",
       "  'Lucros/Prejuízos Acumulados',\n",
       "  'Marcas e Patentes',\n",
       "  'Materiais, Energia, Servs. de Terceiros e Outros',\n",
       "  'Municipais',\n",
       "  'Obrigações Fiscais Estaduais',\n",
       "  'Obrigações Fiscais Federais',\n",
       "  'Obrigações Fiscais Municipais',\n",
       "  'Obrigações Fiscais de Curto Prazo',\n",
       "  'Obrigações Sociais',\n",
       "  'Obrigações Trabalhistas',\n",
       "  'Obrigações Tributárias e Autorizações',\n",
       "  'Outras',\n",
       "  'Outras Contas de Curto Prazo',\n",
       "  'Outras Obrigações Fiscais Federais',\n",
       "  'Outras Obrigações de Curto Prazo',\n",
       "  'Outras Provisões',\n",
       "  'Outras Receitas',\n",
       "  'Outros',\n",
       "  'Outros Ativos Circulantes de Curto Prazo',\n",
       "  'Outros Ativos Circulantes de Longo Prazo',\n",
       "  'Outros Resultados Abrangentes',\n",
       "  'Part. Não Controladores nos Lucros Retidos',\n",
       "  'Participação Minoritária',\n",
       "  'Participação dos Acionistas Não Controladores',\n",
       "  'Participações Societárias',\n",
       "  'Participações em Coligadas',\n",
       "  'Participações em Controladas',\n",
       "  'Passivo Circulante de Curto Prazo',\n",
       "  'Passivo Não Circulante de Longo Prazo',\n",
       "  'Passivo Total',\n",
       "  'Passivos com Partes Relacionadas',\n",
       "  'Passivos com Partes Relacionadas de Longo Prazo',\n",
       "  'Patrimônio Líquido',\n",
       "  'Perda/Recuperação de Valores Ativos',\n",
       "  'Perdas e Aquisições com Não Controladores',\n",
       "  'Pessoal',\n",
       "  'Propriedades para Investimento',\n",
       "  'Provisão/Reversão de Créds. Liquidação Duvidosa',\n",
       "  'Provisões Cíveis',\n",
       "  'Provisões Fiscais',\n",
       "  'Provisões Fiscais Previdenciárias Trabalhistas e Cíveis',\n",
       "  'Provisões Judiciais',\n",
       "  'Provisões Previdenciárias e Trabalhistas',\n",
       "  'Provisões de Curto Prazo',\n",
       "  'Provisões de Longo Prazo',\n",
       "  'Provisões para Benefícios a Empregados',\n",
       "  'Provisões para Garantias',\n",
       "  'Provisões para Passivos Ambientais e de Desativação',\n",
       "  'Provisões para Reestruturação',\n",
       "  'Provisões trabalhistas e cíveis, líquidas',\n",
       "  'Receita de Venda de Bens e/ou Serviços',\n",
       "  'Receitas',\n",
       "  'Receitas Financeiras',\n",
       "  'Receitas refs. à Construção de Ativos Próprios',\n",
       "  'Remuneração Direta',\n",
       "  'Remuneração de Capitais Próprios',\n",
       "  'Remuneração de Capitais de Terceiros',\n",
       "  'Reservas Legais e Estatutárias',\n",
       "  'Reservas de Capital',\n",
       "  'Reservas de Lucros',\n",
       "  'Reservas de Reavaliação',\n",
       "  'Resultado Antes do Resultado Financeiro e dos Tributos',\n",
       "  'Resultado Antes dos Tributos sobre o Lucro',\n",
       "  'Resultado Bruto',\n",
       "  'Resultado Financeiro',\n",
       "  'Resultado de Equivalência Patrimonial',\n",
       "  'Retenção de Lucros e Incentivos Fiscais',\n",
       "  'Retenções',\n",
       "  'Softwares',\n",
       "  'Telecomunicações e Consignações',\n",
       "  'Tributos Parcelados',\n",
       "  'Tributos a Recuperar de Curto Prazo',\n",
       "  'Tributos a Recuperar de Longo Prazo',\n",
       "  'Valor Adicionado Bruto',\n",
       "  'Valor Adicionado Líquido Produzido',\n",
       "  'Valor Adicionado Total a Distribuir',\n",
       "  'Vendas de Mercadorias, Produtos e Serviços',\n",
       "  'Vlr Adicionado Recebido em Transferência',\n",
       "  'Ágio e Reserva Especial']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uv = {}\n",
    "for col in df.columns:\n",
    "    if col not in [\"nsd\", \"value\"]:\n",
    "        uv[col] = sorted(df[col].unique().tolist())\n",
    "uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bovespa Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_company_data(url, base_url=\"https://bvmf.bmfbovespa.com.br/sig/\"):\n",
    "    response = requests.get(url, headers=header_random(), verify=False)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find the relevant table\n",
    "        table = soup.find(\"table\", {\"width\": \"95%\"})\n",
    "\n",
    "        # Initialize lists to store data\n",
    "        company_name = []\n",
    "        trading_name = []\n",
    "        listing = []\n",
    "        ticker = []\n",
    "        # url_mercado = []\n",
    "\n",
    "        if table:\n",
    "            # Iterate through rows of the table and extract data\n",
    "            for row in table.find_all(\"tr\")[1:]:  # Skip the header\n",
    "                columns = row.find_all(\"td\")\n",
    "\n",
    "                # Check if the row has enough columns\n",
    "                if len(columns) >= 4:\n",
    "                    company_name.append(\n",
    "                        clean_text(columns[0].text.strip())\n",
    "                    )  # Razão Social\n",
    "                    trading_name.append(\n",
    "                        clean_text(columns[1].text.strip())\n",
    "                    )  # Nome de Pregão\n",
    "                    listing.append(\n",
    "                        clean_text(columns[2].text.strip())\n",
    "                    )  # Tipo de Mercado\n",
    "                    ticker.append(clean_text(columns[3].text.strip()))  # Sigla\n",
    "\n",
    "                    # # Extract the link\n",
    "                    # link = columns[0].find('a')['href']\n",
    "                    # full_link = f\"{base_url}{link}\"\n",
    "                    # url_mercado.append(full_link)\n",
    "\n",
    "        # Return the extracted data as a DataFrame\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"company_name\": company_name,\n",
    "                \"trading_name\": trading_name,\n",
    "                \"ticker\": ticker,\n",
    "                \"listing\": listing,\n",
    "                # 'url_mercado': url_mercado\n",
    "            }\n",
    "        )\n",
    "        df[\"listing\"] = (\n",
    "            df[\"listing\"].map(settings.governance_levels).fillna(df[\"listing\"])\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_companies_listing():\n",
    "    try:\n",
    "        from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "        # Ignorar avisos de SSL (opcional)\n",
    "        requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "        # List of characters A-Z and 0-9\n",
    "        chars = list(string.digits) + list(string.ascii_uppercase)\n",
    "\n",
    "        # Generate URLs based on each character\n",
    "        base_urls = [\n",
    "            f\"https://bvmf.bmfbovespa.com.br/sig/FormConsultaEmpResultado.asp?strLetraInicial={char}\"\n",
    "            for char in chars\n",
    "        ]\n",
    "\n",
    "        # Initialize an empty DataFrame to store all companies\n",
    "        dfs = []\n",
    "\n",
    "        # Iterate through each URL and fetch the data\n",
    "        start_time = time.time()\n",
    "        for i, url in enumerate(base_urls):\n",
    "            # companies from url\n",
    "            df = parse_company_data(url)\n",
    "            dfs.append(df)\n",
    "\n",
    "            extra_info = [url, f\"{len(df)} companies listed\"]\n",
    "            print_info(i, extra_info, start_time, len(base_urls))\n",
    "\n",
    "        # DataFrame with all companies\n",
    "        companies = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        companies = pd.DataFrame()\n",
    "\n",
    "    return companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_info(soup):\n",
    "    stock_info = {}\n",
    "\n",
    "    # Locate the rows with \"Nome da Ação\" to get stock name and ticker\n",
    "    stock_rows = soup.find_all(\"td\", class_=\"tittabela\", colspan=\"7\")\n",
    "\n",
    "    for row in stock_rows:\n",
    "        stock_text = row.get_text(strip=True)\n",
    "        if \"Nome da Ação\" in stock_text:\n",
    "            # Extract the stock name and ticker (in parentheses)\n",
    "            stock_name = stock_text.split(\"(\")[0].replace(\"Nome da Ação:\", \"\").strip()\n",
    "            stock_ticker = stock_text.split(\"(\")[1].replace(\")\", \"\").strip()\n",
    "\n",
    "            # Add stock_name and stock_ticker to the dictionary\n",
    "            stock_info[stock_name] = stock_ticker\n",
    "    return stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages_to_download(companies, start_date):\n",
    "    tipo = \"RES_MERC_VISTA\"\n",
    "\n",
    "    date_range = [\n",
    "        date.strftime(\"%m-%Y\")\n",
    "        for date in pd.date_range(\n",
    "            start=start_date,\n",
    "            end=pd.Timestamp.today() - pd.offsets.MonthEnd(1),\n",
    "            freq=\"MS\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Generate the items list with ticker, company_name, trading_name, and date\n",
    "    items = [\n",
    "        [row[\"ticker\"], row[\"company_name\"], row[\"trading_name\"], mes]\n",
    "        for _, row in companies.iterrows()\n",
    "        for mes in date_range\n",
    "    ]\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert text with '.' as thousand separator and ',' as decimal separator\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        # Remove thousand separator and replace decimal separator\n",
    "        return float(value.replace(\".\", \"\").replace(\",\", \".\"))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_to_int(value):\n",
    "    try:\n",
    "        # Remove thousand separator and convert to int\n",
    "        return int(value.replace(\".\", \"\").replace(\",\", \"\"))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_trades(soup, stock_info, ticker_code, company_name, trading_name, date):\n",
    "    data = []\n",
    "\n",
    "    # Find all tables that contain daily trading information\n",
    "    tables = soup.find_all(\"table\")\n",
    "\n",
    "    for table in tables:\n",
    "        rows = table.find_all(\"tr\")\n",
    "\n",
    "        for row in rows:\n",
    "            columns = row.find_all(\"td\")\n",
    "            if len(columns) == 12:  # Ensure the row has the expected number of columns\n",
    "                dia = columns[0].get_text(strip=True)\n",
    "                especif = columns[1].get_text(strip=True)\n",
    "\n",
    "                # Convert trades, quantity, and volume to int\n",
    "                trades = convert_to_int(columns[2].get_text(strip=True))\n",
    "                quantity = convert_to_int(columns[4].get_text(strip=True))\n",
    "                volume = convert_to_int(columns[5].get_text(strip=True))\n",
    "\n",
    "                # Convert open, low, high, average, close to float\n",
    "                open = convert_to_float(columns[7].get_text(strip=True))\n",
    "                low = convert_to_float(columns[8].get_text(strip=True))\n",
    "                high = convert_to_float(columns[9].get_text(strip=True))\n",
    "                average = convert_to_float(columns[10].get_text(strip=True))\n",
    "                close = convert_to_float(columns[11].get_text(strip=True))\n",
    "\n",
    "                # Filter out unwanted rows based on some patterns\n",
    "                if \"Negociações\" in dia or \"Dia\" in dia or \"Total\" in dia:\n",
    "                    continue  # Skip unwanted rows\n",
    "\n",
    "                # Combine 'dia' with 'mes' to create a full date\n",
    "                full_date = pd.to_datetime(f\"{dia}-{date}\", format=\"%d-%m-%Y\")\n",
    "\n",
    "                # Split 'Especif.' into stock code and listing\n",
    "                parts = especif.split()\n",
    "\n",
    "                # Map 'ticker_code' from the first part (stock_name) using stock_info\n",
    "                ticker_ = parts[0]\n",
    "                ticker = stock_info.get(\n",
    "                    ticker_, ticker_\n",
    "                )  # Map or fallback to stock_code\n",
    "                ticker_number = \"\".join([char for char in ticker if char.isdigit()])\n",
    "\n",
    "                # Extract 'listing' if available\n",
    "                listing = parts[1] if len(parts) > 1 else None\n",
    "\n",
    "                if listing == \"*\":\n",
    "                    trades = (\n",
    "                        trades * 10\n",
    "                    )  # (transformar lotes de mil em 10 lotes de 100)\n",
    "                    listing = \"\"\n",
    "\n",
    "                # Map 'listing' using the governance_levels dictionary\n",
    "                if listing in settings.governance_levels:\n",
    "                    listing = settings.governance_levels[listing]\n",
    "\n",
    "                # Append row data to the list\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"company_name\": company_name,\n",
    "                        \"trading_name\": trading_name,\n",
    "                        \"ticker_code\": ticker_code + ticker_number,\n",
    "                        \"date\": full_date,\n",
    "                        \"listing\": listing,\n",
    "                        \"trades\": trades,\n",
    "                        \"quantity\": quantity,\n",
    "                        \"volume\": volume,\n",
    "                        \"open\": open,\n",
    "                        \"low\": low,\n",
    "                        \"high\": high,\n",
    "                        \"average\": average,\n",
    "                        \"close\": close,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    df = pd.DataFrame(data).drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.db_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = f\"..\\data\\{settings.db_filepath}\"\n",
    "\n",
    "conn = sqlite3.connect(db_file)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the date range from January 1996 to the current month\n",
    "start_date = \"1991-01\"\n",
    "# start_date = '1986-01'\n",
    "start_date = \"1997-01\"  # temp debug\n",
    "\n",
    "\n",
    "companies = get_companies_listing()\n",
    "pages = get_pages_to_download(companies, start_date)\n",
    "error_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tipo = \"RES_MERC_VISTA\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "start_time = time.time()\n",
    "for i, (ticker_code, company_name, trading_name, date) in enumerate(items):\n",
    "    if [ticker_code, date] not in error_url:\n",
    "\n",
    "        # debug skip\n",
    "        if \"BRSR\" not in ticker_code:\n",
    "            continue\n",
    "\n",
    "        # Fetch the webpage content\n",
    "        url = f\"https://bvmf.bmfbovespa.com.br/sig/FormConsultaMercVista.asp?strTipoResumo={tipo}&strSocEmissora={ticker_code}&strDtReferencia={date}&strIdioma=P&intCodNivel=2&intCodCtrl=160\"\n",
    "        try:\n",
    "            # get page response\n",
    "            response = requests.get(url, headers=header_random(), verify=False)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Parse the HTML using BeautifulSoup\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "                # Check if page has target content\n",
    "                stock_info = fetch_stock_info(soup)\n",
    "\n",
    "                # if page has target content, get data\n",
    "                if stock_info:\n",
    "                    df = fetch_trades(\n",
    "                        soup, stock_info, ticker_code, company_name, trading_name, date\n",
    "                    )\n",
    "                    dfs.append(df)\n",
    "\n",
    "                    # print status\n",
    "                    extra_info = [ticker_code, date, url]\n",
    "                    print_info(i, extra_info, start_time, len(items))\n",
    "                    if i == 129499:\n",
    "                        break\n",
    "\n",
    "                # if not target content, add to error list\n",
    "                else:\n",
    "                    error_url.append([ticker_code, date])\n",
    "\n",
    "                    # print status\n",
    "                    extra_info = [ticker_code, date]\n",
    "                    print_info(i, extra_info, start_time, len(items))\n",
    "\n",
    "            # if response error\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Failed to fetch the page. Status code: {response.status_code}, {i}\"\n",
    "                )\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error requesting {ticker_code}, {date}: {e}\")\n",
    "\n",
    "    # if already checked item for error\n",
    "    else:\n",
    "        print(ticker_code, date)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Example variables\n",
    "tipo = \"RES_MERC_VISTA\"\n",
    "ticker = \"BRSR\"  # Replace this with a value from companies['ticker']\n",
    "mes = \"04/2017\"\n",
    "\n",
    "# Build the base URL\n",
    "base_url = f\"https://bvmf.bmfbovespa.com.br/sig/FormConsultaMercVista.asp?strTipoResumo={tipo}&strSocEmissora={ticker}&strDtReferencia={mes}&strIdioma=P&intCodNivel=2&intCodCtrl=160\"\n",
    "\n",
    "# Fetch the webpage content\n",
    "try:\n",
    "    response = requests.get(base_url, headers=header_random(), verify=False)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        print(f\"URL: {base_url} - Status: {response.status_code} - Success\")\n",
    "\n",
    "        # Locate the tables by finding the table with id \"tblResDiario\"\n",
    "        tables = soup.find_all(\"table\", {\"id\": \"tblResDiario\"})\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to fetch the page. Status code: {response.status_code}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error requesting {base_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1 == 1:\n",
    "    stock_info = {}\n",
    "\n",
    "    # Locate the rows with \"Nome da Ação\" to get stock name and ticker\n",
    "    stock_rows = soup.find_all(\"td\", class_=\"tittabela\", colspan=\"7\")\n",
    "\n",
    "    for row in stock_rows:\n",
    "        stock_text = row.get_text(strip=True)\n",
    "        if \"Nome da Ação\" in stock_text:\n",
    "            # Extract the stock name and ticker (in parentheses)\n",
    "            stock_name = stock_text.split(\"(\")[0].replace(\"Nome da Ação:\", \"\").strip()\n",
    "            stock_ticker = stock_text.split(\"(\")[1].replace(\")\", \"\").strip()\n",
    "\n",
    "            # Add stock_name and stock_ticker to the dictionary\n",
    "            stock_info[stock_name] = stock_ticker\n",
    "\n",
    "stock_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the table data\n",
    "if 1 == 1:\n",
    "\n",
    "# Create a DataFrame and remove duplicates\n",
    "df = pd.DataFrame(data).drop_duplicates()\n",
    "\n",
    "# Display the DataFrame\n",
    "df.iloc[:60]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
